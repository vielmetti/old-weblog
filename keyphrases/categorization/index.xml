<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Categorization on Vacuum weblog from Edward Vielmetti</title>
    <link>http://vielmetti.github.io/keyphrases/categorization/</link>
    <description>Recent content in Categorization on Vacuum weblog from Edward Vielmetti</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Jul 2015 16:11:41 -0400</lastBuildDate>
    <atom:link href="http://vielmetti.github.io/keyphrases/categorization/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Levenshtein distance for approximate match</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-17-levenshtein-distance-for-approximate-match/</link>
      <pubDate>Fri, 17 Jul 2015 16:11:41 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-17-levenshtein-distance-for-approximate-match/</guid>
      <description>&lt;p&gt;The problem, simply stated, is that of typoes and inconsistent
spelling and pluraliziation. Let&amp;rsquo;s say you have a collection of
text that you want to annotate with some metadata, like categories
and tags. You don&amp;rsquo;t want to set aside ahead of time exactly which
tags you want to use, but you want to catch through some test or
lint step that you&amp;rsquo;ve done something wrong by typing &amp;ldquo;apples&amp;rdquo; into
a field that really has &amp;ldquo;apple&amp;rdquo; most of the time. A good algorithm
will catch minor deviations from the norm and advise you when you
should go back with a fresh pair of eyes and do an edit.
The bigger problem is &lt;span style=&#34;background-color: #ffffbf;&#34;&gt;deduplication&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;My first pass at a proposed solution was to look for a version of
the old Unix program &amp;ldquo;uniq&amp;rdquo; that would have an approximate match.
There is also an old Unix program &amp;ldquo;agrep&amp;rdquo; (&amp;ldquo;approximate grep&amp;rdquo;) from
&lt;span style=&#34;background-color: #bfffff;&#34;&gt;Udi Manber&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;[WM92a]
Wu S. and U. Manber, &amp;ldquo;Agrep - A Fast Approximate Pattern-Matching
Tool,&amp;rdquo; Usenix Winter 1992 Technical Conference, San Francisco (January
1992), pp. 153-162.&lt;/p&gt;

&lt;p&gt;Neither of these first lines of attack to see if someone had
completely solved the problem before did the trick, but some
searching around and a conversation with
&lt;span style=&#34;background-color: #bfffff;&#34;&gt;John Hritz&lt;/span&gt;
hit the neuron that remembered the algorithm called the
&lt;span style=&#34;background-color: #ffffbf;&#34;&gt;Levenshtein distance&lt;/span&gt;.
That led me to
&lt;span style=&#34;background-color: #ffbfff;&#34;&gt;Wikibook: Algorithm Implementation&lt;/span&gt;,
and its set of
&lt;a href=&#34;https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance&#34;&gt;Levenshtein distance code&lt;/a&gt;. It so happened that there
was a very slow implementation in the bash shell included
in that collection that was a cut and paste and two lines of
code from being exactly what I needed. A little bit of glue
code in awk and I was ready to go.&lt;/p&gt;

&lt;p&gt;Now the problem with cut and paste two lines of code is that this
particular implmentation is very slow, albeit correct. Given the
choice between slow correct code and fast code that&amp;rsquo;s wrong (because
of the bug that you don&amp;rsquo;t yet understand), I&amp;rsquo;ll take the slow code
plus a comment and a writeup that describes how to make it faster.&lt;/p&gt;

&lt;p&gt;What I&amp;rsquo;m really after is just the pairwise comparison of a set
of words where the two words are close to each other. If the
distance between two words is greater than some threshhold, I don&amp;rsquo;t need
to go any further. That algorithmic shortcut isn&amp;rsquo;t in the library
codes that I found.&lt;/p&gt;

&lt;p&gt;The bigger question is how to write a
checklist
and implement it in code to make sure that a big body of work stays
internally consistent. It&amp;rsquo;s one thing to have a
categorization
rule for your writers that says &amp;ldquo;always use the
singular&amp;rdquo;, but very much something different to have Test 38 in
your automated test corpus apply that rule and notice when it&amp;rsquo;s
wrong.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;Update 29 July 2015:
&lt;span style=&#34;background-color: #bfffff;&#34;&gt;Dennis Yurichev&lt;/span&gt; with a post
&lt;a href=&#34;http://yurichev.com/blog/fuzzy_string/&#34;&gt;Fuzzy string matching + simplest possible spellchecking + hunting for typos and misspellings in Wikipedia.&lt;/a&gt; shares some Python code to handle the
case of automated checking against a probably correct dictionary. He uses this
&lt;a href=&#34;https://pypi.python.org/pypi/python-Levenshtein/0.12.0&#34;&gt;python-Levenshtein&lt;/a&gt; module
to do the hard work.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Categories and their utter impossibility of reflecting the current real world</title>
      <link>http://vielmetti.github.io/post/2013/2013-06-10-categories-and-their-utter-impossibility-of-reflecting-the-current-real-world-/</link>
      <pubDate>Mon, 10 Jun 2013 14:20:13 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-06-10-categories-and-their-utter-impossibility-of-reflecting-the-current-real-world-/</guid>
      <description>&lt;p&gt;
&lt;a class=&#34;asset-img-link&#34; href=&#34;http://vielmetti.typepad.com/.a/6a00d8341c4f1a53ef01901d3de0c9970b-pi&#34; style=&#34;float: right;&#34;&gt;&lt;img alt=&#34;Screen shot 2013-06-10 at 9.55.51 PM&#34; border=&#34;0&#34; class=&#34;asset  asset-image at-xid-6a00d8341c4f1a53ef01901d3de0c9970b&#34; src=&#34;http://vielmetti.typepad.com/.a/6a00d8341c4f1a53ef01901d3de0c9970b-800wi&#34; style=&#34;margin: 0px 0px 5px 5px;&#34; title=&#34;Screen shot 2013-06-10 at 9.55.51 PM&#34; /&gt;&lt;/a&gt;Open up a &amp;quot;New Post&amp;quot; window, start typing.&lt;/p&gt;
&lt;p&gt;Look at the categories on the right side of the screen - my screen, not yours. There&amp;#39;s an infinite scrolling list of them, from &amp;quot;Americana&amp;quot; to &amp;quot;zzz Draft Postings&amp;quot;. Somehow, categories became the wrong way to describe what is in this blog; aside from &amp;quot;Ann Arbor&amp;quot;, there&amp;#39;s few of them that have routine postings. But with almost 3000 articles written, it&amp;#39;s had to imagine any coherent way to recategorize them.&lt;/p&gt;
&lt;p&gt;The problem with categories, buckets, or really any hierarchical system for putting things in one place or another is that there&amp;#39;s always the new thing that defies categorization and asks for its own category. I&amp;#39;m not willing to have a big &amp;quot;Other&amp;quot; category, but I am willing to have an &amp;quot;Oklahoma&amp;quot; category that only gets a few posts a year (earthquakes, tornados).&lt;/p&gt;
&lt;p&gt;I&amp;#39;ve used systems that depend heavily on categorization to make them work. You set up some kind of ongoing task depending on how things or (worse) people are sorted into buckets. Suddenly the world needs bright divisions between one kind of thing and another kind of thing, and any ambiguity about status has to collapse into a single value to make the system make sense.&lt;/p&gt;
&lt;p&gt;Some tools in my experience have been better than others for recategorization. I&amp;#39;ve written before about Maxthink, a 1980s era MS-DOS &amp;quot;idea processor&amp;quot; (still available in Windows) that has a concept of &amp;quot;binsort&amp;quot;, which is an extraordinarily rapid and keyboard-driven way to shuffle and reshuffle items into a hierarchy. That system never really got enough traction to be copied wholesale by any other system, and so it lives on in the world only through dim memories and hardcore users. &lt;/p&gt;
&lt;p&gt;Reshuffling a tree with lots of existing categories is really hard work, because short of wiping out all previous categorization and starting anew you are almost guaranteed to have some vestiges of the old order in place as you&amp;#39;re trying to assert a new set of groupings. Even the infinitely flexible Wikipedia has this problem, as it inherited some parts of its classification system from older encyclopedias like Brittanica.&lt;/p&gt;
&lt;p&gt;So I struggle with sorting through the contents and give up more often than not, relying instead on search rather than careful categorization to unearth old things and to draw relationships among nominally related works. It&amp;#39;s the problem that &lt;a href=&#34;http://www.everythingismiscellaneous.com/&#34; target=&#34;_self&#34;&gt;everything is miscellaneous&lt;/a&gt;&amp;#0160;and too many things are interrelated and that my knowledge of the world too often seems a mile wide and an inch deep.&lt;/p&gt;
&lt;p&gt;Compounding the problem of miscellany is the tendency of our Internet to rot out from under us, with old sites and old links disappearing as people redesign or move on or give up. There&amp;#39;s hardly any way to refer to something without quoting it nearly in full, for fear that when you want to go back to it there will be nothing there to see.&amp;#0160;&lt;/p&gt;
&lt;p&gt;I seem to be rambling, what was the point again? Oh, categories and their utter impossibility of reflecting the current real world and the horrific difficulties of rethinking them half way through your efforts to use them. It so happens that &lt;a href=&#34;http://vielmetti.typepad.com/vacuum/categorization&#34; target=&#34;_self&#34;&gt;I have a categorization category&lt;/a&gt;, which hopefully has some relationship to this brief essay.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>