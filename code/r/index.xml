<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Vacuum weblog from Edward Vielmetti</title>
    <link>http://vielmetti.github.io/code/r/</link>
    <description>Recent content in R on Vacuum weblog from Edward Vielmetti</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Jul 2015 09:55:00 -0400</lastBuildDate>
    <atom:link href="http://vielmetti.github.io/code/r/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Cleaning polygons in R and Shapely</title>
      <link>http://vielmetti.github.io/post/2015/2015-03-04-cleaning-polygons-in-r-and-shapely/</link>
      <pubDate>Wed, 04 Mar 2015 11:14:50 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-03-04-cleaning-polygons-in-r-and-shapely/</guid>
      <description>&lt;p&gt;The project of the week has been an effort to generate a set of
maps - 2935 of them, in fact. The source data is from the Department
of Energy, listing a set of utility companies and the counties they
cover; the goal is to have a boundary map generated for each utility
company. I know it won&amp;rsquo;t be a perfect boundary (most utility companies
have at least one county that they only provide service to part
of), but as a start it&amp;rsquo;s a pretty good one.&lt;/p&gt;

&lt;p&gt;The DOE data is based on their Form EIA-861, and I&amp;rsquo;m working from
the 2013 data set. See &lt;a
href=&#34;http://www.eia.gov/electricity/data/eia861/&#34;&gt;Electric power
sales, revenue, and energy efficiency Form EIA-861 detailed data
files&lt;/a&gt; if you want to get your own files. It&amp;rsquo;s provided as Excel
(XLSX) files, so you&amp;rsquo;ll need something compatible to read them; I
ended up using &lt;a
href=&#34;http://csvkit.readthedocs.org/en/latest/scripts/in2csv.html&#34;&gt;in2csv
from csvkit&lt;/a&gt; as the first part of the pipeline to break these
apart.&lt;/p&gt;

&lt;p&gt;You get lines from the provided file that look like this:&lt;/p&gt;

&lt;pre&gt;
Data Year,Utility Number,Utility Name,State,County
2013,5109,DTE Electric Company,MI,Shiawassee
2013,5109,DTE Electric Company,MI,St Clair
2013,5109,DTE Electric Company,MI,Tuscola
2013,5109,DTE Electric Company,MI,Washtenaw
2013,5109,DTE Electric Company,MI,Wayne
&lt;/pre&gt;

&lt;p&gt;The next challenge is to pull a map for each county served. To do this, convert the (State,County) list to a FIPS code, using a table like this one from ORNL called &lt;a href=&#34;http://cta.ornl.gov/transnet/CoFIPS00.txt&#34;&gt;CoFIPS00.txt&lt;/a&gt;. (MI,Washtenaw) turns into 26161. Feed a list of FIPS codes into the Census Reporter geo API, and out comes GeoJSON files, like so: &lt;a href=&#34;http://api.censusreporter.org/1.0/geo/show/tiger2013?geo_ids=05000US26103,05000US26003&#34;&gt;GeoJSON for Marquette and Alger Counties, Michigan&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;We have a list of counties for each utility, so at minimum we&#39;re set right there. But we need to get 2935 of them, and it&#39;s kind of slow to wait for each one to return before fetching the next one. That motivates the use of &lt;a href=&#34;http://www.gnu.org/software/parallel/&#34;&gt;GNU Parallel&lt;/a&gt;, a shell tool for executing jobs in parallel. On my four core MacBook Air I ran 32 jobs in parallel, and 2935 fetches (using &#34;curl&#34;) took 287 seconds with the median elapsed time for each job at about 3 seconds - about a 31x speedup vs doing things serially.&lt;/p&gt;

&lt;p&gt;However, the GeoJSON provided is really one shape per county, and we&#39;re looking for a complete service area in a single shape, so we need to merge the result together. Here a useful tool is the &#34;R&#34; stats package, particularly the &#34;rgeos&#34;, &#34;rgdal&#34;, and &#34;maptools&#34; packages. &lt;/p&gt;

&lt;p&gt;The first step is the &lt;a href=&#34;http://www.inside-r.org/packages/cran/rgdal/docs/ogrInfo&#34;&gt;readOGR() function from the rgdal library&lt;/a&gt;. It takes a variety of input map formats including GeoJSON and shape files and pulls them into a Spatial vector object in R. rgdal is an R interface to Frank Warmerdam&#39;s &lt;a href=&#34;http://www.gdal.org/&#34;&gt;Geospatial Data Abstraction Library&lt;/a&gt;, and it handles both raster and vector geospatial data formats.&lt;/p&gt;

&lt;p&gt;Next, use the &lt;a href=&#34;http://www.inside-r.org/packages/cran/maptools/docs/unionSpatialPolygons&#34;&gt;unionSpatialPolygons() function from the maptools library&lt;/a&gt; to merge the county polygons into a single polygon. The docs say that this is a wrapper around the &lt;a href=&#34;http://www.inside-r.org/packages/cran/rgeos/docs/gUnion&#34;&gt;gUnion() function from the rgeos library&lt;/a&gt;. rgeos comes from the Google Summer of Code 2010, and this &lt;a href=&#34;https://gsoc2010r.wordpress.com/2010/06/10/rgeos-introduction/&#34;&gt;introduction to the project&lt;/a&gt; explains the motivation. rgeos provides an R interface to &lt;a href=&#34;http://trac.osgeo.org/geos/&#34;&gt;GEOS&lt;/a&gt;, which is in turn a C++ port of &lt;a href=&#34;http://tsusiatsoftware.net/jts/main.html&#34;&gt;JTS&lt;/a&gt;, the Java Topology Suite.&lt;/p&gt;

&lt;p&gt;After you run the unionSpatialPolygons() operation, you will inevitably find that there are tiny holes in your unioned map. Geographic boundaries are complex, and as a result there are often little areas that don&#39;t quite touch, leaving little bits of land that aren&#39;t included anywhere. This algorithm from stackoverflow, &lt;a href=&#34;http://stackoverflow.com/questions/12663263/dissolve-holes-in-polygon-in-r&#34;&gt;Dissolve holes in polygon in R&lt;/a&gt;, takes care of the issue. &lt;/p&gt;

&lt;pre&gt;
G.rings = Filter(function(f){f@ringDir==1},G.union@polygons[[1]]@Polygons)
G.bounds = SpatialPolygons(list(Polygons(G.rings,ID=1)))
&lt;/pre&gt;

&lt;p&gt;As the Polygon documentation note for ringDir: &#34;the ring direction of the ring (polygon) coordinates, holes are expected to be anti-clockwise&#34;&lt;/p&gt;

&lt;p&gt;Having done this cleanup work, we return a GeoJSON file with the &lt;a href=&#34;http://www.rdocumentation.org/packages/leafletR/functions/toGeoJSON&#34;&gt;toGeoJSON() function from the leafletR package&lt;/a&gt;. Now I probably don&#39;t need to pull in all of leafletR; there&#39;s a &lt;a href=&#34;http://www.inside-r.org/packages/cran/rgdal/docs/writeOGR&#34;&gt;writeOGR() function in the rgdal package&lt;/a&gt; that should also do the same work. The aside, though, is that &lt;a href=&#34;https://github.com/chgrl/leafletR&#34;&gt;leafletR&lt;/a&gt; creates nice maps in R using the &lt;a href=&#34;http://leafletjs.com/&#34;&gt;Leaflet&lt;/a&gt; Javascript library.&lt;/p&gt;

&lt;p&gt;With all that done, we have a new GeoJSON file that&#39;s a cleaned up merge of multiple county outlines done in R. However, the process isn&#39;t quite done. Some of the merged files don&#39;t have holes, but they do have &#34;slivers&#34;, little angular bits of geometry from where two counties don&#39;t quite touch at their corners. I didn&#39;t find an algorithm to unsliver in R, but this &lt;a href=&#34;http://gis.stackexchange.com/questions/120286/removing-small-polygons-gaps-in-a-shapely-polygon&#34;&gt;Removing small polygons gaps in a Shapely polygon&lt;/a&gt; did the trick. &lt;/p&gt;

&lt;pre&gt;
# Here&#39;s the algorithm
fx = poly.buffer(eps, 1, join_style=JOIN_STYLE.mitre).buffer(-eps, 1, join_style=JOIN_STYLE.mitre)
&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://toblerity.org/shapely/manual.html&#34;&gt;Shapely&lt;/a&gt; from Sean Gilles is a &#34;Python package for set-theoretic analysis and manipulation of planar features using (via Pythonâ€™s ctypes module) functions from the well known and widely deployed GEOS library.&#34; So we&#39;re back to GEOS, which is also supported by R...which means I suspect this algorithm translates directly back into R by proper invocation of the equivalent &lt;a href=&#34;http://www.inside-r.org/packages/cran/rgeos/docs/gBuffer&#34;&gt;gBuffer() function from the rgeos package&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;No matter, I installed Shapely. It&#39;s pretty fast, and if I had time to refine this operation I&#39;d try to port all of the R code back into python using Shapely to see if I could get a meaningful speedup improvement.&lt;/p&gt;

&lt;p&gt;All this description! Here&#39;s the code.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/vielmetti/13f6feae14111ff1c148&#34;&gt;unsliver.py&lt;/a&gt; - in Python with the Shapely library&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/450495defeff6e4d1440&#34;&gt;mergeGeoJSON.Rscript&lt;/a&gt; - in R with rgeos, sp, rgdal, maptools, and leafletR&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And here&#39;s a picture:&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/vielmetti/2a6feadf268ca2b686e7.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Thanks go to Joe Germuska (for Census Reporter and csvkit), Markus Spath (for R help), Matt Hampel (for mapping help), Jacob Wasserman (for Shapely help), Stan Gregg (for outage mapping), Mohan Kartha (for GNU Parallel and AWS help), and anyone else who I missed along the way.                                          &lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Daily coffee and wifi at Argus Farm Stop</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-24-daily-coffee-wifi-argus-farm-stop/</link>
      <pubDate>Fri, 24 Jul 2015 09:55:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-24-daily-coffee-wifi-argus-farm-stop/</guid>
      <description>&lt;p&gt;Daily coffee and wifi at Argus Farm Stop, outside in the sunshine
under a lovely red umbrella canopy. Espresso over ice and a day-old
olive twist. The view is of a Sky Trak lift at the construction
site across moving materials to the back of The Mark, a building
that&amp;rsquo;s going up where the car wash used to be.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;The news of the day is a death on State Street. A young man was
climbing over the skylights at the Nickels Arcade and fell to his
death when the skylight glass gave way.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;On July 24, 1915, the SS Eastland was packed with employees from
the Western Electric Hawthorne Works when it rolled over in
the Chicago River. 844 passengers and crew lost their lives, making
the Eastland disaster the worst shipwreck on the Great Lakes.
See the &lt;a href=&#34;http://www.eastlanddisaster.org/&#34;&gt;Eastland Disaster Historical Society&lt;/a&gt;
for extensive notes on and photos of the scene and its aftermath.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;The next meeting of &lt;a href=&#34;http://www.meetup.com/a2civictech/&#34;&gt;a2civictech&lt;/a&gt;
is coming up on Monday, July 27, 2015.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;&lt;a href=&#34;http://www.literatibookstore.com/&#34;&gt;Literati Bookstore&lt;/a&gt; is open
again after a water leak caused them to shut down.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;A few months ago I wrote a tiny R script that generates maps. The challenge
today is to find a portable environment so that I can deploy this script
on shared infrastructure. The project took 30 minutes of MacBook Air processor
time running full blast parallel, and while I don&amp;rsquo;t care about wall clock time
to complete the effort I do care about building something that I can hand
off to someone else to run.&lt;/p&gt;

&lt;p&gt;The hope is that the &lt;a href=&#34;https://github.com/rocker-org/ropensci&#34;&gt;ropensci&lt;/a&gt; Docker
package from the Rocker project is the answer, or most of the answer, for this.
Rocker has built R images where lots of useful packages have been installed,
including systems where the install directions are a little bit complex.&lt;/p&gt;

&lt;p&gt;With all complicated software environments the biggest challenge is dealing
with dependencies. If you want to use the latest and greatest fast algorithms,
you have to be prepared to spin up on what the cool kids are doing in the
rest of their environment. If somehow you can jump to the edge of the development
in the algorithm world without being tripped up by the hairy dependency graph
that got you there, it can be a lot more fun.&lt;/p&gt;

&lt;p&gt;So; install Docker on the Mac with &amp;lsquo;boot2docker&amp;rsquo;; then&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull rocker/ropensci
docker run -it rocker/ropensci R
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and poof, you have an environment current to this month&amp;rsquo;s desktop of leading
R developers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Maps with Leaflet and LeafletR</title>
      <link>http://vielmetti.github.io/post/2015/2015-03-02-maps-with-leaflet-and-leafletr/</link>
      <pubDate>Mon, 02 Mar 2015 01:09:35 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-03-02-maps-with-leaflet-and-leafletr/</guid>
      <description>&lt;pre&gt;
&gt; style &lt;- styleGrad(prop=&#34;score&#34;, breaks=seq(50,100,by=10) ,style.val=rev(rainbow(5)), leg=&#34;score&#34;)
&gt; leaflet(data=&#34;/Users/emv/tmp/N.geojson&#34;,dest=tempdir(),popup=&#34;*&#34;,style=style)
&lt;/pre&gt;

&lt;p&gt;So, progress.&lt;/p&gt;

&lt;p&gt;One process, written in python, takes an Excel file provided by the county and creates a GeoJSON file from it. Addresses in the file are geocoded. The original file has a set of restaurant inspection reports and three kinds of inspection problems found; I add a fourth &#34;score&#34; variable that&#39;s derived in some way from those three.&lt;/p&gt;

&lt;p&gt;A second process (code above) is in R using the LeafletR graphing package. It in turn takes the GeoJSON file as originally provided, and writes an HTML file that reads it using the Leaflet maps package.&lt;/p&gt;

&lt;p&gt;A screenshot of the result is below:&lt;/p&gt;

&lt;p&gt;&lt;a class=&#34;asset-img-link&#34;  href=&#34;http://vielmetti.typepad.com/.a/6a00d8341c4f1a53ef01b7c7572bc9970b-pi&#34;&gt;&lt;img class=&#34;asset  asset-image at-xid-6a00d8341c4f1a53ef01b7c7572bc9970b img-responsive&#34; style=&#34;width: 600px; display: block; margin-left: auto; margin-right: auto;&#34; alt=&#34;Screen Shot 2015-03-02 at 12.56.42 AM&#34; title=&#34;Screen Shot 2015-03-02 at 12.56.42 AM&#34; src=&#34;http://vielmetti.typepad.com/.a/6a00d8341c4f1a53ef01b7c7572bc9970b-600wi&#34; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Some big caveats.&lt;/p&gt;

&lt;p&gt;My color palette is all wrong - I need to think that through. &lt;/p&gt;

&lt;p&gt;This process is based on a single monthly Excel file, and should be updated to include all recent inspections and not just a single month.&lt;/p&gt;

&lt;p&gt;The map needs labels of some sort. (How they will look when everything is smushed together, don&#39;t know.)&lt;/p&gt;

&lt;p&gt;It would be nice to have HTML links to the Arborwiki page for each restaurant, and to a deep link for the inspections itself.&lt;/p&gt;

&lt;p&gt;The geocoder is a bit slow, and I should cache previous results so that it goes faster in future months.&lt;/p&gt;

&lt;p&gt;RESTAURANT NAMES ARE IN ALL CAPS AND THAT&#39;S SHOUTING.&lt;/p&gt;

&lt;p&gt;Leaflet can do all sorts of things and I&#39;ve hardly scratched the surface.&lt;/p&gt;

&lt;p&gt;I probably could do this all in R - or all in Python - but I&#39;m trying to spin up on both systems &amp;amp; thus really want to use each for what they are good at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>food coop notes for July 18, 2015</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-18-food-coop-notes/</link>
      <pubDate>Sat, 18 Jul 2015 14:23:56 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-18-food-coop-notes/</guid>
      <description>&lt;p&gt;Some notes over a cup of coffee and some cold roast chicken. I need
to mix up my menu selections at the coop more so that I can remember
what I was writing by what I ate; I usually eat the same thing!&lt;/p&gt;

&lt;p&gt;Peter Honeyman and Lynn Chamberlain were here at the coop, doing
the NY Times crossword. (Saturday crossword in 36:05, a mid-day triumph.)&lt;/p&gt;

&lt;p&gt;At Farmer&amp;rsquo;s Market: cherries, parsley, kale, potatoes, dill, tomatoes.
The potatoes will be boiled and dressed with a dill vinaigrette.
(I had to look up the word vinaigrette.) The recipes I found add
green beans and boiled eggs to a salad with cold potatoes, using
a mustard vinaigrette with added chopped dill. The cherries will
probably just be eaten out of hand.&lt;/p&gt;

&lt;p&gt;The UP travel discussion included the obligatory discussion of insects,
including ticks (&amp;ldquo;like bedbugs, for the woods&amp;rdquo;) and horrible sand
flies that will swarm you and leave you screaming running from the
beach. There&amp;rsquo;s a good reason that the UP has miles of undeveloped beaches.&lt;/p&gt;

&lt;p&gt;You can&amp;rsquo;t mention bugs in the UP without remembering
&lt;a href=&#34;http://somethingscrawlinginmyhair.com/&#34;&gt;The Backyard Arthropod Project&lt;/a&gt;,
&amp;ldquo;A Field Guide to the North Side of Old Mill Hill, Atlantic Mine, MI&amp;rdquo;,
by Tim Eisele.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m still hacking away at generating interesting reports from
the &lt;a href=&#34;https://github.com/markvanderloo/stringdist&#34;&gt;stringdist&lt;/a&gt;
package from Mark van der Loo. Yesterday&amp;rsquo;s post was
&lt;a href=&#34;http://stackoverflow.com/questions/31486913/r-producing-a-list-of-near-matches-with-stringdist-and-stringdistmatrix&#34;&gt;R: producing a list of near matches with stringdist and stringdistmatrix&lt;/a&gt; and the answers provided
helped unearth the melt() function from the reshape2 library,
and with &lt;em&gt;that&lt;/em&gt; you take a matrix and turn it into an edge list.
A little bit of filtering, and you get a report of near matches
in a list, enough for me to catch variant spellings of
vinagrette to vinaigrette in a &amp;ldquo;make test&amp;rdquo; step.&lt;/p&gt;

&lt;p&gt;Stack Overflow was fun for this task, I&amp;rsquo;m going to try it again.
The process of describing your problem in enough detail that someone
who knows the issue can add the one or two lines of code to make
it work is a useful exercise. It&amp;rsquo;s the opposite of a search
engine in many ways - of course I could find melt() once I know
its name, but if you don&amp;rsquo;t know the name you can&amp;rsquo;t find anything.&lt;/p&gt;

&lt;p&gt;The next bit of interestingness has to do with turning the dist
data structure returned by stringdist into a variety of useful
images. There&amp;rsquo;s a package that dumps out a &amp;ldquo;dendogram&amp;rdquo;, and if I&amp;rsquo;m
careful in formatting the data I think I can coerce R into producing
data that can be imported directly into the tools that
Valdis Krebs
has written for network exploration and visualization. The
promise within R is a &amp;ldquo;distgraph&amp;rdquo; that does the visualization,
but I&amp;rsquo;m not yet finding the cadre of experts who use that.&lt;/p&gt;

&lt;p&gt;The art on the walls is Julie Marron-Parker&amp;rsquo;s &amp;ldquo;Sunburst&amp;rdquo;. She writes&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Let the sun shine.&lt;/p&gt;

&lt;p&gt;Living in Michigan (160 days of sun per year) I have come to
appreciate when the sun is out. This piece brings the energy of the
sun into the world, regardless of the weather outside.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Tom Meloche writes about &lt;a href=&#34;http://tommeloche.com/the-doorway-effect/&#34;&gt;the doorway effect&lt;/a&gt;,
where going through a doorway wipes out your short term memory
to make way for new short term memories. It got me thinking
about the &lt;span style=&#34;background-color: #ffffbf;&#34;&gt;memory palace&lt;/span&gt;, and how you might construct
in your mind a series of portals and doorways to walk through so
that you can remember a series of items in such a way that you
take advantage of the doorway effect to pull memories in and out
of your short term thinking. The technology is &amp;ldquo;mnemotechnics&amp;rdquo;,
that&amp;rsquo;s a good keyword to pull lots of interesting thinking
(which sometimes sounds like crazytalk).&lt;/p&gt;

&lt;p&gt;That reminds me - I need to move to another room, so that I can
remember what I need to do here.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>