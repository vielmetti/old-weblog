<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Selenium on Vacuum weblog from Edward Vielmetti</title>
    <link>http://vielmetti.github.io/code/selenium/</link>
    <description>Recent content in Selenium on Vacuum weblog from Edward Vielmetti</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Jun 2015 12:58:34 -0400</lastBuildDate>
    
	<atom:link href="http://vielmetti.github.io/code/selenium/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Automating web testing and scraping with Selenium and the Firefox Selenium IDE</title>
      <link>http://vielmetti.github.io/post/2015/2015-06-24-automating-web-testing-and-scraping-with-selenium-and-the-firefox-selenium-ide/</link>
      <pubDate>Wed, 24 Jun 2015 12:58:34 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-06-24-automating-web-testing-and-scraping-with-selenium-and-the-firefox-selenium-ide/</guid>
      <description>You might like me occasionally want to pull a bit of data from some web site and use that data in a script or process. Some modern web sites are fiendishly complex and don&#39;t have the data you want on a simple API or page that you can parse; instead, you&#39;re expected to navigate through a whole next of menus and links that present the data attractively.
I&#39;m making a go of tackling this task with Selenium, a browser automation system which can drive browsers like Firefox and Chrome and that can in turn be driven by programming languages like Python.</description>
    </item>
    
  </channel>
</rss>