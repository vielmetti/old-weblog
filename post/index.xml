<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Post-rsses on Vacuum weblog from Edward Vielmetti</title>
    <link>http://vielmetti.github.io/post/index.xml</link>
    <description>Recent content in Post-rsses on Vacuum weblog from Edward Vielmetti</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Jan 9999 00:00:00 -0400</lastBuildDate>
    <atom:link href="http://vielmetti.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>About this weblog</title>
      <link>http://vielmetti.github.io/post/about-this-weblog/</link>
      <pubDate>Fri, 01 Jan 9999 00:00:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/about-this-weblog/</guid>
      <description>&lt;p&gt;Edward Vielmetti has been writing the Vacuum weblog
since 1999 from Ann Arbor, Michigan. The topics vary
widely, with over 2000 entries in the whole collection.&lt;/p&gt;

&lt;p&gt;In the interest of simplifying the presentation, some
parts of this collection are currently offline, and the
front page represents primarily current work and not
a diversity of interests.&lt;/p&gt;

&lt;p&gt;The current set of systems that are an area of focus -
and the places I draw from for inspiration on each -
are as follows. One might loosely couple these together
under the intersection of &amp;ldquo;DevOps&amp;rdquo; and the &amp;ldquo;Internet of Things&amp;rdquo;, but that
would be an oversimplification at many levels.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/sdr/&#34;&gt;Software defined radio&lt;/a&gt;.
Building radio receivers and decoders in software. I&amp;rsquo;m
using an &lt;a href=&#34;http://vielmetti.github.io/tags/rtl-sdr/&#34;&gt;RTL-SDR&lt;/a&gt;
tuner stick and the &lt;a href=&#34;http://vielmetti.github.io/tags/dump1090/&#34;&gt;dump1090&lt;/a&gt;
software as a way of getting ADS-B data that decodes to
airplane locations. From listening to distant radio
stations to decoding digital modes, SDR tools rapidly
are transforming the nature of radio experimentation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/rpi/&#34;&gt;Raspberry Pi&lt;/a&gt;. This little ARM based single board computer
is a launching point for small scale situated experimental
computing interfaces to the outside world. I&amp;rsquo;m running
the &lt;a href=&#34;http://blog.hypriot.com&#34;&gt;Hypriot&lt;/a&gt; distribution on my
systems, which provides infrastructure to run Docker.
Pis are cheap and cheerful, and the ARM chips they are
built from have applications all the way from disposable
embedded computers to data center scale power efficient compute farms.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/embedded&#34;&gt;Embedded controllers&lt;/a&gt; with wireless data. Products like
Particle&amp;rsquo;s Electron and the Hologram Dash systems point the
way to a future where small battery-operated devices
have some kind of always-on global connectivity. Battery
constraints and power consumption are the biggest considerations,
and there&amp;rsquo;s a wide variety of possible radio frequencies and
associated chipsets to be evaluated.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/docker&#34;&gt;Docker&lt;/a&gt;. This tool allows you to encapsulate system dependencies
so that even complex software can be launched and run
without going through an extensive installation process.
Run this on small systems like the Raspberry Pi, for development on OS X or Linux,
and on servers like CoreOS on EC2. Container technology
and cluster technology are still changing rapidly, with
every new release offering new functions (and the risk of
a smattering of interesting new bugs).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/coreos&#34;&gt;CoreOS&lt;/a&gt;.
This minimalist operating system is designed primarily
to run Docker containers and to handle system updates automatically.
As long as your services can handle being rebooted periodically
for externally scheduled system updates, it does a great job
of providing a stable platform for container-first system designs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/aws&#34;&gt;Amazon Web Services&lt;/a&gt;.
The sprawling set of Amazon capabilities
means that you should never need to have a data center of your
own, so long as you manage to figure out how to economically
build systems out of their mostly (but not completely) reliable
infrastructure. When AWS goes down, though, watch out - it&amp;rsquo;s likely
to break in some novel way that your application, no matter how
well engineered, will not expect to see.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/aws-iot&#34;&gt;AWS IoT&lt;/a&gt;.
This Amazon Web Services stack provides a message
broker based on MQTT, plus a set of services for triggering
functions in AWS Lambda when messages come in and a database
capture with AWS DynamoDB. It&amp;rsquo;s still an open question how
expensive this system is at scale.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/aws-lambda&#34;&gt;AWS Lambda&lt;/a&gt;.
Instead of running Amazon Web Services one computer at a time,
you run it one function call at a time. With support for
Python and node.js, Lambda is an example of &amp;ldquo;serverless&amp;rdquo;
computing, where the unit of compute resource you are
marshalling to solve a problem is just as small as you can
make it.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/mqtt&#34;&gt;MQTT&lt;/a&gt;.
This simple publish-subscribe message broker standard
lets very small systems communicate with the cloud in a method
that doesn&amp;rsquo;t require that the remote system have a globally
routed address.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vielmetti.github.io/tags/node-red&#34;&gt;Node-RED&lt;/a&gt;.
This IBM community project provides a nice drag and drop interface
for building message-oriented prototype software and hardware
interfaces. Built on top of node.js and npm, it also offers
neatly encapsulated access to hundreds of javascript libraries.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Happy leap second (or mostly happy) and happy new year for 2017</title>
      <link>http://vielmetti.github.io/post/2017/2017-01-01-leap-second/</link>
      <pubDate>Sun, 01 Jan 2017 10:00:01 -0500</pubDate>
      
      <guid>http://vielmetti.github.io/post/2017/2017-01-01-leap-second/</guid>
      <description>

&lt;p&gt;Happy new year, and from a technology perspective, also happy leap second.&lt;/p&gt;

&lt;p&gt;[image: timekeeping for the leap second, from FSM Labs]
&lt;blockquote class=&#34;twitter-tweet&#34; data-partner=&#34;tweetdeck&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Here&amp;#39;s a complete picture of &lt;a href=&#34;https://twitter.com/hashtag/leapsecond?src=hash&#34;&gt;#leapsecond&lt;/a&gt; 2016. &lt;a href=&#34;https://t.co/DFp6XgnPig&#34;&gt;pic.twitter.com/DFp6XgnPig&lt;/a&gt;&lt;/p&gt;&amp;mdash; FSMLabs (@FSMLabs) &lt;a href=&#34;https://twitter.com/FSMLabs/status/815589123121618944&#34;&gt;January 1, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;As always, when there&amp;rsquo;s a leap second, people get a chance to debug their
timekeeping code. I guess if they happen frequently enough the code will
get better exercise and some bugs will be shaken out. Every time
some government messes with timekeeping, a small army of programmers gets
a few hours of work to adjust their systems, with some occasional unplanned downtime.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.fsmlabs.com&#34;&gt;FSMLabs&lt;/a&gt; watched the time change closely, and their image above
shows one peculiarity of reported time: Google&amp;rsquo;s NTP servers
returned a time that was up to half a second off, slowly creeping
out of sync with real time and then back into sync. They write
in a recap, &lt;a href=&#34;http://www.fsmlabs.com/news/2017/01/01/2leapsecondskew2016.html&#34;&gt;Leapsecond 2016 complete&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can see that Google starts its 20 hour leap-second “skew” 10 hours before the event and then skews back to the real time. Everyone else stays correct and then has a short error as they “leap” the second and then come back into correct time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;FSMLabs sells precision timekeeping equipment aimed at the financial
industry.&lt;/p&gt;

&lt;h3 id=&#34;leap-second-bugs&#34;&gt;Leap second bugs&lt;/h3&gt;

&lt;p&gt;The biggest issue identified was at Cloudflare, a distributed system
for web cachine.
&lt;a href=&#34;https://www.cloudflarestatus.com/incidents/1fczgjmknplp&#34;&gt;Some DNS lookups causing 5xx errors due to leap second bug&lt;/a&gt;
is the incident report.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Starting at 00:00 UTC on January 1, 2017, CNAME resolutions on some machines stopped working due to a bug triggered by the universal addition of one leap second, which affected both some authoritative DNS and origin DNS lookups, causing 5xx errors.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the real world, the biggest reported issue that could be
suspicious was reported by the BBC as &lt;a href=&#34;http://www.bbc.com/news/uk-38482746&#34;&gt;London ambulance service hit by new year fault&lt;/a&gt;,
an account of computer system crashes at London Ambulance Service (LAS)
that are peculiarly synchronized with the appearance of the leap second.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It is understood the computer system crashed, so calls had to be recorded by pen and paper for nearly five hours on one of the busiest nights of the year.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;systemd-is-eating-the-world&#34;&gt;Systemd is eating the world&lt;/h3&gt;

&lt;p&gt;Finally in timekeeping news and notes, the &lt;a href=&#34;https://coreos.com/os/docs/latest/configuring-date-and-timezone.html&#34;&gt;CoreOS help pages for timekeeping&lt;/a&gt;
illustrate the importance of keeping good time within a computing cluster.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;CoreOS clusters use NTP to synchronize the clocks of member nodes, and all machines start an NTP client at boot. CoreOS versions later than 681.0.0 use systemd-timesyncd(8) as the default NTP client. Earlier versions used ntpd(8). Use systemctl to check which service is running:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;ldquo;Systemd is eating the world&amp;rdquo;, and one of the things it has eaten is timekeeping.
One of the old CoreOS bugs, &lt;a href=&#34;https://github.com/coreos/bugs/issues/391&#34;&gt;systemd-timesyncd not as precise as ntpd&lt;/a&gt;,
reports that because of systemd-timesyncd&amp;rsquo;s less precise timekeeping there
are problems with Deis and Ceph. The bug report is from 2015 and was closed
due to inactivity, but if you have weird problems with CoreOS, Deis, and Ceph,
check your clocks!&lt;/p&gt;

&lt;h3 id=&#34;notes-and-references&#34;&gt;Notes and references&lt;/h3&gt;

&lt;p&gt;The future timekeeping bug that&amp;rsquo;s most likely to create worldwide
angst on the scale of Y2K is the
&lt;a href=&#34;https://en.wikipedia.org/wiki/Year_2038_problem&#34;&gt;Year 2038 problem&lt;/a&gt;,
which I&amp;rsquo;m counting on helping fix to fund my retirement.&lt;/p&gt;

&lt;p&gt;TimeAndDate News has a &lt;a href=&#34;https://www.timeanddate.com/news/time/&#34;&gt;time zone news&lt;/a&gt; feed,
which is useful to track worldwide adjustments to and from Daylight Savings Time.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://community.ntppool.org/t/leap-second-2017-status/59&#34;&gt;NTP Pool leap second 2017 status&lt;/a&gt;
reported that as of a few hours before the leap second, 3463 servers in the pool system were announcing the leap second and 933 were not.
&lt;a href=&#34;https://community.ntppool.org/users/ask/activity&#34;&gt;Ask Bjørn Hansen&lt;/a&gt; maintains the pool since 2005.&lt;/p&gt;

&lt;p&gt;Hail truechimers, exit falsetickers!&lt;/p&gt;

&lt;h4 id=&#34;updated-2017-01-01t16-07-00-to-add-fsm-labs-london-ambulance-notes-headers&#34;&gt;Updated 2017-01-01T16:07:00 to add FSM Labs, London Ambulance notes, headers&lt;/h4&gt;
</description>
    </item>
    
    <item>
      <title>Watching containers with Portainer and Sysdig</title>
      <link>http://vielmetti.github.io/post/2016/2016-12-28-watching-containers-with-portainer-and-sysdig/</link>
      <pubDate>Wed, 28 Dec 2016 23:30:00 -0500</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-12-28-watching-containers-with-portainer-and-sysdig/</guid>
      <description>&lt;p&gt;[screen capture: csysdig running inside Portainer]&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-partner=&#34;tweetdeck&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Run &lt;a href=&#34;https://twitter.com/sysdig&#34;&gt;@sysdig&lt;/a&gt; CLI tool &amp;quot;csysdig&amp;quot; inside of a &lt;a href=&#34;https://twitter.com/portainerio&#34;&gt;@portainerio&lt;/a&gt; console window. Nice way to watch &lt;a href=&#34;https://twitter.com/docker&#34;&gt;@docker&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/coreos&#34;&gt;@coreos&lt;/a&gt; cc &lt;a href=&#34;https://twitter.com/mckartha&#34;&gt;@mckartha&lt;/a&gt; &lt;a href=&#34;https://t.co/hJGiHuJwKs&#34;&gt;pic.twitter.com/hJGiHuJwKs&lt;/a&gt;&lt;/p&gt;&amp;mdash; Edward Vielmetti (@vielmetti) &lt;a href=&#34;https://twitter.com/vielmetti/status/814320562294181888&#34;&gt;December 29, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The question to be answered is how to manage Docker containers - not
just how to get them running, but also how to poke inside them while
they are running to see what they are doing and make sure that you
can make sense of what is happening while you develop or run in production.&lt;/p&gt;

&lt;p&gt;At &lt;a href=&#34;http://vielmetti.github.io/post/2016/2016-12-19-tectonic-2016-trip-report/&#34;&gt;Tectonic&lt;/a&gt; I was introduced to one tool that handles Docker
and Kubernetes container introspection, &lt;a href=&#34;http://sysdig.com&#34;&gt;Sysdig&lt;/a&gt;. From Twitter I
also discovered &lt;a href=&#34;http://portainer.io&#34;&gt;Portainer&lt;/a&gt;, a nice system for container management.
Having installed both Portainer and Sysdig, the interesting bit
happens when you connect the together.&lt;/p&gt;

&lt;p&gt;Portainer provides a very high level view of your container
infrastructure, with an easy browser level access to see what
containers you have loaded on the system, what&amp;rsquo;s running, and how
to start or restart or pull new containers. Sysdig on the other
hand has a very low level kernel&amp;rsquo;s eye view of the system, watching
every system call and timing it and providing a system browser (with
&amp;ldquo;csysdig&amp;rdquo;) that is reminiscent of faithful Unix tools like &amp;lsquo;htop&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;First, install each of them according to package instructions.
As of this writing (December 2016) Portainer will run on Intel
and ARM platforms, but Sysdig really wants to run on Intel only.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://portainer.readthedocs.io/en/latest/deployment.html&#34;&gt;Portainer install instructions&lt;/a&gt;
will want you to pull the latest version (v1.11) and then
set a password. The vision for Portainer product direction
is full role based access control, so expect developments
here; just know that for now, if you want an admin password
to persist, you&amp;rsquo;ll have to persist the data in the filesystem
or in a Docker storage volume. As installs go, this is pretty
easy.&lt;/p&gt;

&lt;p&gt;Next, you&amp;rsquo;ll want to follow the &lt;a href=&#34;http://www.sysdig.org/install/&#34;&gt;Sysdig install instructions&lt;/a&gt;
for installing Sysdig in a container. We&amp;rsquo;re monitoring CoreOS,
which makes the effort directly supported; I haven&amp;rsquo;t done Ubuntu yet.
Sysdig wants to have a kernel module installed, and the CoreOS
install effort takes advantage of automated new kernel builds whenever
CoreOS does a new release.&lt;/p&gt;

&lt;p&gt;Once both systems are up, connect them together. You&amp;rsquo;ll want to
connect to a running sysdig container through the console, via
the navigation path dashboard / containers / sysdig / console.
Launch a console window on your Sysdig container, and in that console
run &amp;ldquo;csysdig -pc&amp;rdquo;. You&amp;rsquo;ll have a view on the innards of your containers.&lt;/p&gt;

&lt;p&gt;Now the biggest missing piece is the amount of this narrative
given over to install instructions, rather than use instructions.
Portainer has some very nice ways to install a variety of containerized
applications, but it doesn&amp;rsquo;t know how to launch Sysdig in a single
click, nor is it reasonable to naively assume that it can. Even once
you get the command line invocation right there may be a pesky
requirement to get kernel headers all exactly correct. Still, if
possible that would be the direction I&amp;rsquo;d give to both organizations -
make it easier to embed Sysdig tools and functions inside a Portainer framework.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trip report, Tectonic 2016.</title>
      <link>http://vielmetti.github.io/post/2016/2016-12-19-tectonic-2016-trip-report/</link>
      <pubDate>Mon, 19 Dec 2016 12:00:00 -0500</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-12-19-tectonic-2016-trip-report/</guid>
      <description>

&lt;p&gt;The &lt;a href=&#34;https://tectonic.com/summit/&#34;&gt;Tectonic Summit&lt;/a&gt; was a conference in New York City in December 2016, hosted
by &lt;a href=&#34;https://coreos.com/&#34;&gt;CoreOS&lt;/a&gt;, with the theme &lt;em&gt;Enterprise Kubernetes&lt;/em&gt;. Mohan Kartha and
Edward Vielmetti went there as a guest of &lt;a href=&#34;http://packet.net&#34;&gt;Packet&lt;/a&gt;, a bare-metal hosting
provider in the city. This report details highlights of the presentations
at the event as well as accounts from attendees of what they thought
was missing from the presentation and discussions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cncf/landscape/master/landscape/CloudNativeLandscape_v0.9.2.jpg&#34; style=&#34;max-width=100%&#34;/&gt;&lt;/p&gt;

&lt;h3 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; is an orchestration system that runs on top of a container
system like &lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;. It allows an enterprise or service provider to
define a system that can scale up and down according to need. &lt;a href=&#34;http://blog.kubernetes.io/2016/12/kubernetes-1.5-supporting-production-workloads.html&#34;&gt;Version 1.5 of Kubernetes&lt;/a&gt;
was announced during the event, and it has extended
beyond the previous version by speeding up operations so that it can
support larger clusters.&lt;/p&gt;

&lt;p&gt;The Kubernetes project is relatively young, but it draws from
the experience of Google&amp;rsquo;s &amp;ldquo;Borg&amp;rdquo; program. Version 1.0 came
out about two years ago, and there have been tens of thousands
of contributions to the codebase since then.&lt;/p&gt;

&lt;h3 id=&#34;kubernetes-project-management-openstack-docker-comparison&#34;&gt;Kubernetes project management; OpenStack, Docker comparison&lt;/h3&gt;

&lt;p&gt;The Kubernetes project is run by the &lt;a href=&#34;https://www.cncf.io/&#34;&gt;Cloud Native Computing Foundation&lt;/a&gt;,
which is about 50% by weight Google and the rest other cloud providers
like Amazon. There was some political discussion at the event where it
was clear that Kubernetes proponents made an effort to distance themselves
from the &lt;a href=&#34;http://www.openstack.org/foundation&#34;&gt;OpenStack Foundation&lt;/a&gt;. &lt;a href=&#34;http://www.openstack.org&#34;&gt;OpenStack&lt;/a&gt; was what people were doing
a few years ago to solve a similar set of problems, and that project
has floundered because of a combination of vendor-induced complexity
and a set of designs that did not reflect actual operation practice.
While the Kubernetes folks were all polite to OpenStack, they were
clear that they did not want to be tarred with the same brush.&lt;/p&gt;

&lt;p&gt;The other product positioning and political interest at the event was
how various organizations were dealing with &lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;. That company
controls the container system that is being orchestrated by Kubernetes,
but also has been clawing its way up the stack acquiring other organizations
that do container management and monitoring and developing additional
capacities beyond the container core.  &lt;a href=&#34;https://www.docker.com/products/docker-swarm&#34;&gt;Docker Swarm&lt;/a&gt; competes with
Kubernetes, in the same way that the &lt;a href=&#34;https://coreos.com/rkt/&#34;&gt;rkt&lt;/a&gt; container engine competes
with [containerd] provided by Docker. The Kubernetes
team would really rather have a vendor-neutral, stable, drama free
container engine, rather than one that mutates all the time.&lt;/p&gt;

&lt;h3 id=&#34;self-driving-kubernetes-tectonic-from-coreos&#34;&gt;Self-driving Kubernetes: Tectonic from CoreOS&lt;/h3&gt;

&lt;p&gt;The major product announcement at the event was from CoreOS, their
namesake &lt;a href=&#34;https://tectonic.com/&#34;&gt;Tectonic&lt;/a&gt; product. The latest release of Tectonic is said to
be &amp;ldquo;self-driving&amp;rdquo;, i.e. will upgrade the version of Kubernetes on
a cluster automatically. Their observation was that people who
run Kubernetes spend an inordinate amount of time outside of Kubernetes
upgrading systems when a new version comes out, and that there was
an opportunity to remove that burden by automatically handling
upgrades using a strategy much like CoreOS&amp;rsquo;s own &lt;a href=&#34;https://coreos.com/os/docs/latest/&#34;&gt;Container Linux&lt;/a&gt;
which automagically installs new versions when they are available.&lt;/p&gt;

&lt;p&gt;Tectonic is now available with a &lt;a href=&#34;https://coreos.com/press/tectonic-self-driving.html&#34;&gt;free 10-node license&lt;/a&gt;. This is
a new pricing strategy aimed at capturing the trial and test user
market and offering an easier self-service onramp to getting started
with the system.&lt;/p&gt;

&lt;h3 id=&#34;sysdig-kubernetes-monitoring-and-debugging-tool&#34;&gt;Sysdig, Kubernetes monitoring and debugging tool&lt;/h3&gt;

&lt;p&gt;Kubernetes monitoring was demonstrated by &lt;a href=&#34;http://www.sysdig.org/&#34;&gt;Sysdig&lt;/a&gt;, which has a product
both for individual system monitoring and for container monitoring
of Kubernetes and Docker systems. There is lots of complexity in the container
world, with processes moving here and there and logical systems
dispersed across physical machines. sysdig starts with a robust
monitoring and introspection technology that can replace lots of
one-shot Linux monitoring tools (ps, top, sysstat etc) and extends
that tool function all the way up into Kubernetes.&lt;/p&gt;

&lt;p&gt;Provided for a fee is &lt;a href=&#34;https://sysdig.com/sysdig/&#34;&gt;Sysdig Cloud&lt;/a&gt; which puts a point-and-click GUI interface on
Kubernetes networking so that you get the whole picture at whatever
level of detail you want. Sysdig&amp;rsquo;s CEO also presented in Chicago at Docker Chicago.&lt;/p&gt;

&lt;h3 id=&#34;helm-kubernetes-provisioning-tool&#34;&gt;Helm, Kubernetes provisioning tool&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://helm.sh&#34;&gt;Helm&lt;/a&gt; was described as &amp;ldquo;like apt-get for Kubernetes&amp;rdquo;; it promises to make
deployment of systems easier by allowing a prepackaged set of commands
and configurations to be distributed through a central registry or
produced for your own private use. Every system needs a package manager.&lt;/p&gt;

&lt;h3 id=&#34;case-studies-ticketmaster-planet&#34;&gt;Case studies: Ticketmaster, Planet&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/rossdakin/status/808323710381920256&#34;&gt;Ticketmaster&lt;/a&gt; was the main customer case study provided. Their system
architecture support a very large, complex, heterogeneous workload
with very old legacy stuff in the core of it (an old Vax, with its
brain pickled into an emulator). The ticketing business model is
a &amp;ldquo;self-induced DDOS attack&amp;rdquo; with very bursty loads when tickets
go on sale. They use Kubernetes to schedule containers so as to
handle peak loads better.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.planet.com/&#34;&gt;Planet&lt;/a&gt; was a second case study, which does global daily hi res
satellite imagery.  Their previous operations environment deployed
VMs with Ansible, which led to a relatively slow deployment process
in which every image had crazy dependencies. Docker helps contain
dependency interactions.  Kubernetes helps scheduling and deployment
of resources as they are needed, so they can spin up and spin down
resources specific to a task and not have to guess what part of the
world their users are interested in today.&lt;/p&gt;

&lt;h3 id=&#34;storage-the-missing-link&#34;&gt;Storage, the missing link&lt;/h3&gt;

&lt;p&gt;Notably missing from the discussion was a comprehensive look at
storage. People had seemed to have sorted out at least the basics
of networking and compute distribution over these large workloads,
but anyone who had large storage needs had worked out something
specific and purpose-built to their environment.&lt;/p&gt;

&lt;p&gt;I had a conversation with the CTO of Quantum who is
the project lead for &lt;a href=&#34;https://rook.io/&#34;&gt;Rook&lt;/a&gt; which uses an embedded &lt;a href=&#34;https://www.mail-archive.com/ceph-users@lists.ceph.com/msg34143.html&#34;&gt;Ceph&lt;/a&gt; filesystem.
Ceph is one of the file systems that has come out of the
cluster world, and Rook is an attempt to cut it down to
size and simplify it so that it can be easily embedded
as container storage.&lt;/p&gt;

&lt;p&gt;No one really wants to write a file system from scratch and use it
in production that same year. The most mature file systems are decades
old and have a long history of correctness and performance tweaks.
Of all things to worry about people are largely unwilling to put
production loads on untested storage.&lt;/p&gt;

&lt;h3 id=&#34;kubernetes-progress-development-testing-deployment&#34;&gt;Kubernetes progress: development, testing, deployment&lt;/h3&gt;

&lt;p&gt;What people are using Kubernetes for: mostly for testing. The average
size of a cluster is less than 3 nodes, according to a Gartner
analyst.  &lt;a href=&#34;bare metal hosting&#34;&gt;Packet&lt;/a&gt; has seen uptake as a Kubernetes
test environment - it&amp;rsquo;s cheaper to provision bare metal than AWS or VMs
for Kubernetes, and performant enough for the test environment.&lt;/p&gt;

&lt;h3 id=&#34;arm-in-the-data-center&#34;&gt;ARM in the data center.&lt;/h3&gt;

&lt;p&gt;We had a good lunch discussion of ARM processors in the data center. Question:
is there any way to displace Intel&amp;rsquo;s dominance of data center
computing?  ARM has advantages at very low end due to low power
consumption, and the 4-core ARM Raspberry Pi 3 is a popular testbed for home clustering
but not suitable for data center use. Packet has a &lt;a href=&#34;https://www.packet.net/bare-metal/servers/type-2a/&#34;&gt;96-core ARMv8 server&lt;/a&gt;
that we have been involved in testing, and there was lots of interest in
stories around that.&lt;/p&gt;

&lt;p&gt;The challenges of ARM in the data center: Intel dominance on software
side, some small amount of fragmentation in Unix flavors, immaturity
of software ports to ARMv8 (even as compared to ARMv7), unconvincing
economics. One ex-Transmeta guy was very pessimistic about displacing
Intel because of Intel&amp;rsquo;s manufacturing lead. On the other hand a Khosla Ventures
exec was bullish on &lt;a href=&#34;http://www.cavium.com&#34;&gt;Cavium&lt;/a&gt;, an ARM server core vendor, and thought they
had a long way to grow. He was interested in a call back in 30 - 90
days with report on uptake.&lt;/p&gt;

&lt;h3 id=&#34;site-visit-packet-net&#34;&gt;Site visit: Packet.net&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://packet.net&#34;&gt;Packet&lt;/a&gt; provides bare metal as a service, either in your data
center or their own. The office was very busy and bursting at the
seams, with people sitting everywhere and a steady stream of vendors and
partners in evidence. Packet are very nice, prompt, pleasant people to deal
with, and they are expanding to new markets (Japan) with new
investment (Softbank) on new servers (ARMv8).&lt;/p&gt;

&lt;p&gt;The hosting market was explained to me this way: some companies have OpEx to
spend, so they spend it on AWS; others have CapEx to spend, so they
are trying to build a data center operating platform that&amp;rsquo;s friendly
to using on premises. Can you run your system on other people&amp;rsquo;s
capital? The Packet founders have been through this before and seem to have
built a culture that knows its market.&lt;/p&gt;

&lt;h3 id=&#34;in-conclusion&#34;&gt;In conclusion&lt;/h3&gt;

&lt;p&gt;Good conference, and thanks to CoreOS for organizing the event
and to Packet for inviting us to participate!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tiresome telegraphy</title>
      <link>http://vielmetti.github.io/post/2016/2016-12-19-tiresome-telegraphy/</link>
      <pubDate>Mon, 19 Dec 2016 09:00:00 -0500</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-12-19-tiresome-telegraphy/</guid>
      <description>&lt;p&gt;I really should stop writing words for Twitter Inc. and start again writing essays or book chapters. So much telegraphy is tiresome.&lt;/p&gt;

&lt;p&gt;I enjoy the cadence of a well-formed 140 character sentence. It&amp;rsquo;s a good width to set your typewriter to for composition.
Set it to 132 for writing, leaving 8 characters free as a sequence number in case you drop your card deck and need to sort.
&amp;ldquo;Twitter like COBOL&amp;rdquo;, writes Tom Brandt; I was thinking more of FORTRAN dusty decks that are too precious to scramble.
Draw a diagonal line across the deck so that if it does get scrambled, you can put it back together. Use a monospace font.
&amp;ldquo;Wrap your deck in the greenbar output&amp;rdquo;, writes Bob Allen, &amp;ldquo;and rubberband it tightly.&amp;rdquo; Jef Poskanzer illustrates.&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;und&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/vielmetti&#34;&gt;@vielmetti&lt;/a&gt; &lt;a href=&#34;https://t.co/uwuBoKkwdU&#34;&gt;pic.twitter.com/uwuBoKkwdU&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jef Poskanzer (@jef_poskanzer) &lt;a href=&#34;https://twitter.com/jef_poskanzer/status/810511409666736128&#34;&gt;December 18, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The instant nature of telegraphy is its appeal. You type, and the listeners on the wire get a galvanic jolt an instant later.
If you are fortunate, they respond in turn, and you have what feels like electric heart-to-heart communications. Zap! Magic!
It feels spontaneous, but beware: the insistent response that you considered heartfelt is but a zero point fluctuation.
Someone else is hoping for a response to their tweet, and you bounce a spark back and forth until the spark is spent.
Then silence again, and the wire goes quiet except for sparkless bots, one-way news drips and sports scores.&lt;/p&gt;

&lt;p&gt;We mistake an instant response as deep attention, and pay less attention to the carefully worded replies that come later.
Long-delayed responses are indistinguishable from failure to communicate, and quick replies are self-evident signs of life.
&amp;ldquo;Watson, come quickly&amp;rdquo;, and the test is the speed of the reaction, not the thoughtfulness of the response.
How do you revisit that urge for instant speed and replace it with something that allows contemplation? Not in Twitter, I fear.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve written a lot of words into the tweetstream - more than plenty enough words to compose an entire novel.
The question is whether there&amp;rsquo;s a novel has already been written, and just needs to be edited to bring it to market.
The raw materials are already there, so what matters is only some level of diligence and digging and sorting to make it whole.&lt;/p&gt;

&lt;p&gt;Charles Dickens syndicated his novels through magazines, one chapter written after another and posted as it was fresh.
He had a full month to produce each installment, and at times was working on two works simultaneously.&lt;/p&gt;

&lt;p&gt;Dickens on the telegraph, 1850, &lt;a href=&#34;http://www.bl.uk/collection-items/wings-of-wire-from-household-words&#34;&gt;Wings of Wire&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I prefer to think of it as a syndicated essay, sent in fragments over the wire one line at a time.
It&amp;rsquo;s up to the recipient to reassemble the fragments and to call out when there&amp;rsquo;s a missing piece.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimal Opera</title>
      <link>http://vielmetti.github.io/post/2016/2016-12-19-optimal-opera/</link>
      <pubDate>Mon, 19 Dec 2016 08:00:00 -0500</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-12-19-optimal-opera/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m testing out using Opera instead of Chrome as my browser of choice, as recommended by Ernie Smith.  So far so good.
He notes that Opera is &amp;ldquo;basically Chrome (same engine) minus the battery drain&amp;rdquo;.
My experience to date bears that out, though it&amp;rsquo;s in the early stages yet.&lt;/p&gt;

&lt;p&gt;The first thing I noticed is that memory usage for Opera is way less than for Chrome.
That&amp;rsquo;s a big deal for me because I&amp;rsquo;m often noticing that this MacBook Air is in the red zone for memory with Chrome.
With Opera that&amp;rsquo;s not the case so far - memory has been green since starting.
This should also translate into less SSD disk activity for swapping, and better battery life.&lt;/p&gt;

&lt;p&gt;The default configuration includes a lot of interesting features, including an ad blocker and a VPN.
Both of those are interesting, but not a complete replacement for the tools I&amp;rsquo;m looking for.&lt;/p&gt;

&lt;p&gt;The ad blocker is speedy, but it doesn&amp;rsquo;t block the comments on MLive, which is a pity - Ghostery did that well.
Fortunately, Ghostery is supported on Opera, so I can have two ad blockers running at once to get the desired result.
Opera counts the number of ads blocked. I don&amp;rsquo;t know if Ghostery&amp;rsquo;s blocked ads are double-counted.&lt;/p&gt;

&lt;p&gt;The VPN is set up to work with a public VPN endpoint, but I can&amp;rsquo;t configure it to use my private endpoint.
There are a number of other VPN plugins (plugsin?) available, each connecting to their own set of endpoints.
I&amp;rsquo;d like a general-purpose VPN tool that allows me to run my own endpoint, but I haven&amp;rsquo;t found one yet.&lt;/p&gt;

&lt;p&gt;I didn&amp;rsquo;t import all of my bookmarks and cookies and passwords, which is a attempt to stay away from Facebook.
Ask me how much time I spend (or waste) on Facebook! There must be a better use of your time than that.
&lt;a href=&#34;https://mathbabe.org/2016/12/06/i-quit-facebook-and-my-life-is-better-now/&#34;&gt;Quit Facebook and make your life better&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Derp Learning</title>
      <link>http://vielmetti.github.io/post/2016/2016-11-24-derp-learning/</link>
      <pubDate>Thu, 24 Nov 2016 15:00:00 -0500</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-11-24-derp-learning/</guid>
      <description>&lt;p&gt;&amp;ldquo;Derp Learning&amp;rdquo; is a categorization of the mistakes that &amp;ldquo;deep learning&amp;rdquo; techniques
in artificial intelligence tend to make. It&amp;rsquo;s a typo, but also a deep insight into
how complex systems fail.&lt;/p&gt;

&lt;p&gt;Some examples to illustrate:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1412.1897&#34;&gt;Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images&lt;/a&gt;, 2014.
Nguyen describes &amp;ldquo;fooling images&amp;rdquo; that deep neural networks misclassify after being
trained with a training set. These images are straightforward to construct and
will fool the network with high confidence.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.dailydot.com/debug/tay-racist-microsoft-twitter/&#34;&gt;Microsoft&amp;rsquo;s racist robot and the problem with AI development&lt;/a&gt;,
The Daily Dot, 2016. Microsoft&amp;rsquo;s conversational chatbot &amp;ldquo;Tay&amp;rdquo; undergoes some unsupervised learning from Twitter,
and emerges as a racist Holocaust denier.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bbc.com/news/technology-38092196?ocid=socialflow_twitter&#34;&gt;Convict-spotting algorithm criticised&lt;/a&gt;, BBC, 2016.
A &lt;a href=&#34;https://arxiv.org/pdf/1611.04135v2.pdf&#34;&gt;paper&lt;/a&gt; from Wu and Zhang purports to find that
Chinese faces can be automatically classified as criminal based on facial
characteristics such as the curvature of the upper lip. This &amp;ldquo;research&amp;rdquo;
hearkens back to the bad old days of phrenology when criminologists
predicted behavior based on the bumps on people&amp;rsquo;s heads.&lt;/p&gt;

&lt;p&gt;Artificial intelligence doesn&amp;rsquo;t kill people; training data kills people.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Static vulnerability analysis tools for Docker containers</title>
      <link>http://vielmetti.github.io/post/2016/2016-10-28-static-vulnerability-analysis/</link>
      <pubDate>Fri, 28 Oct 2016 10:30:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-10-28-static-vulnerability-analysis/</guid>
      <description>&lt;p&gt;You&amp;rsquo;re developing in Docker, and you have a container with a lot of layers
when you&amp;rsquo;re done. How do you make sure that you don&amp;rsquo;t have security vulnerabilities
hiding somewhere inside there, especially if you are running a container that
depends on something that depends on something that depends on something else?&lt;/p&gt;

&lt;p&gt;The first step is to understand your own application, so that you can have some
sense for how the dependencies that you have control over are impacted. This
is actually a more difficult problem than you&amp;rsquo;d expect, since a lot of
packages are in turn dependent on other packages and so on and so on.
I&amp;rsquo;ve used &lt;a href=&#34;https://gemnasium.com/&#34;&gt;Gemnasium&lt;/a&gt; to help with this. It tracks
Ruby, Node.js, Python, and PHP dependencies, and generates alerts when
a package has a known issue that should trigger an update.
The &lt;a href=&#34;https://nodesecurity.io/&#34;&gt;Node Security Project&lt;/a&gt; has a similar
service, focused on Node.js, and has an integration directly into
Github so that you can verify and validate every commit against their
vulnerability analysis.&lt;/p&gt;

&lt;p&gt;Next, make certain that your Dockerfiles are following best practices
by checking them with &lt;a href=&#34;https://dockerbench.com/&#34;&gt;Docker Bench for Security&lt;/a&gt;,
which is a portable shell script that checks for dozens of common
practices that are good for security.&lt;/p&gt;

&lt;p&gt;One of the difficult practices that&amp;rsquo;s common to Dockerfiles is the
tendency for people to work their way around package managers in
the install process, to avoid the sometimes hefty overhead of maintaining
a package index. When you install a package with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl | tar &amp;amp;&amp;amp; ./configure &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;instead of RPM or apk or apt or your distribution&amp;rsquo;s favorite package
manager, it can be very hard to keep track of precisely which version
that incantation actually put into place.&lt;/p&gt;

&lt;p&gt;Assuming that your application is now somehow clear from any issues under your
direct control, the next step is to track down and understand operating
system vulnerabilities. One approach that I&amp;rsquo;ve read about but not used
yet is the open source &lt;a href=&#34;https://coreos.com/blog/vulnerability-analysis-for-containers/&#34;&gt;Clair&lt;/a&gt;
from CoreOS. Clair does static analysis of containers, using a set of
vulnerability databases that are parsed down to a Postgres database.
There&amp;rsquo;s a certain amount of complexity in the whole thing, and as a
result it&amp;rsquo;s not trivial to integrate this into a continuous integration
process (though that task has been done at least once).&lt;/p&gt;

&lt;p&gt;Docker has its own &lt;a href=&#34;https://docs.docker.com/docker-cloud/builds/image-scan/&#34;&gt;Docker Security Scanning&lt;/a&gt;,
which is available to paid accounts.&lt;/p&gt;

&lt;p&gt;One of the big issues in handling static analysis of Docker containers
is that a popular and small Docker base image, Alpine Linux, is not
covered by Clair in part because Alpine does not have a fully machine
parsable vulnerability analysis database. The Clair project is
&lt;a href=&#34;https://github.com/coreos/clair/issues/12&#34;&gt;working on the issue&lt;/a&gt;, but
they are hampered in part by the small size of the Alpine team and
their focus on code vs. documentation. From
&lt;a href=&#34;http://lists.alpinelinux.org/alpine-devel/5231.html&#34;&gt;a post to alpine-devel in 2016&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;we try do more the actual work, than the paperwork ;-)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Doing continuous integration on a complex project with multiple open
source dependencies can pose tricky issues, especially when you&amp;rsquo;re
dealing with code that is at or near end of life. If you discover
that the vulnerability is in a component that has been removed from
active development, yet you depend on it, you may be forced to either
live with a known bug or undertake expensive porting efforts to
get back to a good state. For example, Node-RED used the &lt;code&gt;ws&lt;/code&gt;
package from npm, at a version known to have a denial of service
attack. &lt;a href=&#34;https://github.com/node-red/node-red/issues/931&#34;&gt;This issue persists&lt;/a&gt;
as of late October 2016 because of the project&amp;rsquo;s desire to continue
to support Raspberry Pi hardware with the default operating system load.
The Pi&amp;rsquo;s base Raspbian system uses Node.js at 0.10 which is now
obsolete, and the fixes to &lt;code&gt;ws&lt;/code&gt; don&amp;rsquo;t include 0.10 patches.&lt;/p&gt;

&lt;p&gt;What exactly are you running, how do you know that it&amp;rsquo;s free of
known issues, and how can you mitigate or fix the problems you
find? It&amp;rsquo;s hard to do dynamic analysis at scale, because of
the likelihood that bugs exist that can escape your testing
environment. Static analysis looks like a reasonable alternative
(assuming that the components themselves are well tested), but
the increasingly layered nature of modern software development
means that this is a hard, hard task.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using SDR.HU to listen to AM radio sports</title>
      <link>http://vielmetti.github.io/post/2016/2016-10-23-sdr-hu-am-dx-baseball-and-football/</link>
      <pubDate>Sun, 23 Oct 2016 00:15:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-10-23-sdr-hu-am-dx-baseball-and-football/</guid>
      <description>&lt;p&gt;The Cubs won the pennant, and the Buckeyes lost to Penn State. I was able to listen to
the radio calls of both of these through recievers connected to &lt;a href=&#34;http://sdr.hu&#34;&gt;sdr.hu&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The Cubs radio call was from WMVP-AM, ESPN Chicago 1000. I had some practice listening
to them through the Farmington Hills, MI SDR run by KB8SPI. That system is a KiwiSDR
with a PA0RDT Mini-Whip, and it tunes from 0-30 Mhz including all of the longwave
(broadcast AM) band. I also had a chance to pull in WTAM-AM Newsradio 1100 in Cleveland
from the same receiver, though I had to work a bit to avoid adjacent channel interference
from WCAR-AM 1090 in Detroit.&lt;/p&gt;

&lt;p&gt;The Ohio State call was from WIMA-AM, Lima Ohio 1150. This was very easy to pick up from
KH6ILT&amp;rsquo;s KiwiSDR in nearby Elida, OH. WIMA is part of the Ohio State IMG Sports Network,
and it broadcasts all of the Buckeye football games. The signal is very strong (S9+30)
and there is no interference from other stations. I was able to find this station from
the &lt;a href=&#34;http://www.ohiostatebuckeyes.com/sports/m-footbl/spec-rel/radio-network.html&#34;&gt;list of Ohio State Buckeye radio stations&lt;/a&gt;,
and it&amp;rsquo;s possible that this particular receiver might pick up other sports broadcasts as well;
I&amp;rsquo;m also able to pull in WMVP-AM ESPN Chicago 1000 here.&lt;/p&gt;

&lt;p&gt;Chasing AM radio sports is a lot of fun. Even if the major networks broadcast their
video streams via cell phone apps for free from time to time - ESPN was showing
the Ohio State game on their app at the end for free - it&amp;rsquo;s still useful to pick
up the radio call. In this particular case the radio feed was a couple of plays
ahead of the video, so I got about 45 seconds of lead time by listening to the radio.&lt;/p&gt;

&lt;p&gt;The only small limitation about SDR.HU and its OpenWebRX software is that when I
try to view it on a small cell-phone sized screen it doesn&amp;rsquo;t handle it very well.
Note that these receivers are based on the Beaglebone hardware and can only handle
four simultaneous listeners. With those two constraints in mind, it&amp;rsquo;s a great way
to extend your listening reach.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>More 96 core benchmarks</title>
      <link>http://vielmetti.github.io/post/2016/2016-10-15-more-96-core-benchmarks/</link>
      <pubDate>Sat, 15 Oct 2016 00:00:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-10-15-more-96-core-benchmarks/</guid>
      <description>&lt;p&gt;Yesterday I spent some time with a 96 core ARMv8 server.
On day two I figured out a couple more things about that
server.&lt;/p&gt;

&lt;p&gt;First and foremost, the extended path of installing Docker
on the server I chronicled yesterday ended up being much
easier today. A simple&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get install docker.io
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;did the right thing to bring Docker 1.12.1 into the system.
Don&amp;rsquo;t do&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get install docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;on Ubuntu; you&amp;rsquo;ll get &amp;ldquo;docker - System tray for KDE3/GNOME2
docklet applications&amp;rdquo; instead. The
&lt;a href=&#34;https://blog.docker.com/2014/04/docker-in-ubuntu-ubuntu-in-docker/&#34;&gt;original release announcement for Docker on Ubuntu&lt;/a&gt;
explains why.&lt;/p&gt;

&lt;p&gt;To characterize performance on real workloads,
I compiled some packages from
source. I did my best to force parallelism in the build.
&lt;a href=&#34;https://www.gnu.org/software/make/manual/html_node/Parallel.html&#34;&gt;GNU Make supports a &amp;ldquo;-j&amp;rdquo; flag&lt;/a&gt;
that tries to run more jobs at
once, and that makes a big difference.
It&amp;rsquo;s worth reading makefiles before you build on a system
like this, because there may be special considerations for
parallel builds.&lt;/p&gt;

&lt;p&gt;Node.JS master built in 4.5 minutes, about a 38x speedup.&lt;/p&gt;

&lt;p&gt;Go for linux/arm64 built in under 9 minutes instead of an hour.&lt;/p&gt;

&lt;p&gt;With the help of the hosting provider, we also looked at power
consumption of the server. Reported power used when idle was 212 watts,
and the reported power under a heavy workload by the &lt;code&gt;stress&lt;/code&gt;
test harness was about 80 watts more, at 292 watts. Roughly
speaking that&amp;rsquo;s 2 watts per core idle, and 3 watts per core
when loaded.
&lt;a href=&#34;http://people.seas.harvard.edu/~apw/stress/&#34;&gt;Stress&lt;/a&gt; is from
Amos Waterland; it runs nicely on Posix systems.&lt;/p&gt;

&lt;p&gt;There is a version of &lt;code&gt;firefox&lt;/code&gt; for the system that installs
with &lt;code&gt;apt-get install firefox&lt;/code&gt;, and I forwarded X11 from the
data center to the cafe to see how it worked. It loads fine,
but visiting pages like umich.edu result in a failure. I didn&amp;rsquo;t
find an easy bug repository to report that too, but it was
repeatable. If I do this again, I&amp;rsquo;ll&lt;/p&gt;

&lt;p&gt;The &amp;ldquo;build Docker from scratch&amp;rdquo; project resulted in the
&lt;a href=&#34;https://github.com/docker/docker/issues/27384&#34;&gt;build failing with TestOverlay128LayerRead&lt;/a&gt;, which is an issue with the overlay2 filesystem.
It turns out that&amp;rsquo;s a much more interesting bug than
yesterday&amp;rsquo;s Docker bug, since we can pinpoint how
many layers can be overlaid (61, but not 62) before the
failure.&lt;/p&gt;

&lt;p&gt;One of the things I tested is
&lt;a href=&#34;https://code.facebook.com/posts/1840075619545360&#34;&gt;Facebook&amp;rsquo;s new &amp;ldquo;yarn&amp;rdquo; package&lt;/a&gt;
manager for Node.JS - it seemed to work just fine, but
I had hoped that it would have some kind of bonus speed from
parallelism, and I didn&amp;rsquo;t see that. Node is notably not
a parallel language.&lt;/p&gt;

&lt;p&gt;All in all a good day of trying to understand what the
high performance world looks like when you have lots and
lots of little cores. This is obviously not a server for
every workload, but for the ones that match it should be great.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>96 cores hot with ARMv8 and Docker</title>
      <link>http://vielmetti.github.io/post/2016/2016-10-14-96-cores-hot-with-armv8/</link>
      <pubDate>Fri, 14 Oct 2016 00:15:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-10-14-96-cores-hot-with-armv8/</guid>
      <description>&lt;p&gt;I had early access to a 96 core, 128 gigabyte ARMv8 server today. Here&amp;rsquo;s
what I did to get all of the CPUs and all of the memory in use at the same
time.&lt;/p&gt;

&lt;p&gt;The system: a bare-metal hosting company is working on general availability
of these ARMv8 (aarch64) servers. I got early access for beta testing.
Talk to me if you&amp;rsquo;d like to know more.&lt;/p&gt;

&lt;p&gt;The software: These systems boot with Ubuntu 16.04 which is plenty modern
to run lots of workloads. The challenge I had was that there was no Docker
available to download via apt-get. So, off to build my own.&lt;/p&gt;

&lt;p&gt;A starting point: I began with this writeup of
&lt;a href=&#34;http://blog.hypriot.com/post/getting-docker-running-on-a-high-density-armv8-server-from-hisilicon/&#34;&gt;running Docker on ARMv8 from HiSilicon&lt;/a&gt;
written by the Hypriot folks. They lovingly and carefully document getting
Docker going on a 16-core system, starting from Ubuntu 15.04. There are
enough differences in the config that I had to adapt, but not so many
that I was in foreign territory.&lt;/p&gt;

&lt;p&gt;Go: The 96 core system has Go 1.6.2 installed out of the box, so I didn&amp;rsquo;t
have to bootstrap that. That saved a bunch of time.&lt;/p&gt;

&lt;p&gt;Building Docker without having a Docker server running is a trick. The
Hypriot team describes it thusly:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For this purpose there is an easy, but not really well-known workaround. We have to check and install the necessary development dependencies first and then we can run the build script natively to get a first working Docker binary. So, let’s do it right away.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Follow their instructions closely, and you get a build of v1.10.2 of
Docker, which you can copy into the bin directories and run directly.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time AUTO_GOPATH=1 ./hack/make.sh dynbinary
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Systemd was happy after I dug out the right service
files for docker.service and docker.socket. Just copy the docker binaries
into place, reload systemd, and you&amp;rsquo;re almost good to go. Almost, because
you need to make sure you create /var/run/docker.sock which allows
communications between the client and server.&lt;/p&gt;

&lt;p&gt;Next attempt was to build the &amp;ldquo;master&amp;rdquo; release, and there I wasn&amp;rsquo;t
able to successfully do a complete build because the &lt;code&gt;aufs&lt;/code&gt; tests
did not all pass.  (See the &lt;a href=&#34;https://github.com/docker/docker/issues/27357&#34;&gt;open ticket&lt;/a&gt; for the details.)&lt;/p&gt;

&lt;p&gt;After some time of building Docker over and over from source, and not
getting tests to pass, I gave up and declared victory. Hooray! Someone
who knows more about file systems can push the next step forward.&lt;/p&gt;

&lt;p&gt;To test this system, Mohan Kartha pointed me at Marek Goldmann&amp;rsquo;s
excellent treatise on &lt;a href=&#34;https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/&#34;&gt;resource management in Docker&lt;/a&gt;.
He uses a system testing tool called &lt;code&gt;stress&lt;/code&gt; running inside a Docker
container to exercise workloads. As a note to get this test running,
you need to slightly change the provided Dockerfile, to read as follows
to pick up an aarch64 version of Fedora.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM resin/aarch64-fedora:latest
RUN yum -y install stress &amp;amp;&amp;amp; yum clean all
ENTRYPOINT [&amp;quot;stress&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Build this Dockerfile and then run as follows to give a 96 core system
a good workout. Install htop first so you get a good colorful screen to watch.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -it --rm stress --cpu 96 --io 96 --vm 96 --vm-bytes 4G --timeout 100s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;. &lt;a href=&#34;https://twitter.com/Quintus23M&#34;&gt;@Quintus23M&lt;/a&gt; &lt;a href=&#34;https://twitter.com/docker&#34;&gt;@docker&lt;/a&gt; docker 1.10.2 + &amp;quot;stress&amp;quot; exercising all 96 cores and all 128G of memory. cc &lt;a href=&#34;https://twitter.com/mckartha&#34;&gt;@mckartha&lt;/a&gt; &lt;a href=&#34;https://t.co/kPm8JWUJKR&#34;&gt;pic.twitter.com/kPm8JWUJKR&lt;/a&gt;&lt;/p&gt;&amp;mdash; Edward Vielmetti (@vielmetti) &lt;a href=&#34;https://twitter.com/vielmetti/status/786773896691261440&#34;&gt;October 14, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;I saved away some binaries on a couple of systems so that reinstalling should
be straightforward once this machine gets destroyed, and then off we go.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AWS Lambda for Python with &#34;Chalice&#34;</title>
      <link>http://vielmetti.github.io/post/2016/2016-10-13-aws-lambda-with-chalice/</link>
      <pubDate>Thu, 13 Oct 2016 00:15:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-10-13-aws-lambda-with-chalice/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/chalice&#34;&gt;Chalice&lt;/a&gt; is a microframework for Python for &lt;a href=&#34;https://aws.amazon.com/lambda/&#34;&gt;AWS Lambda&lt;/a&gt;,
similar in spirit to &lt;a href=&#34;http://flask.pocoo.org/&#34;&gt;Flask&lt;/a&gt;. What does that even mean?&lt;/p&gt;

&lt;p&gt;A framework is a set of libraries and coding conventions
that makes development in a specific language for a specific
task easier. That usually involves making some simplifying
assumptions about the task you are trying to solve, and
embedding those assumptions in your code so that you don&amp;rsquo;t
have to spell out quite as much detail to get a task done.&lt;/p&gt;

&lt;p&gt;A microframework is a small version of a framework, and the
work echoes the current 2016 in-favor design principle of
microservices, where instead of building some all-singing,
all-dancing monolithic application that does everything,
you figure out some components that can stand alone and be
simplified away from the big thing so that they can change
faster.&lt;/p&gt;

&lt;p&gt;What do you do with a microframework for Python for AWS Lambda?
Well, you develop microservices in Lambda. Lambda is a hosting
environment on Amazon Web Services that is ideal for very
short lived processes or even just function calls that last
a few seconds (&amp;ldquo;micro&amp;rdquo;) and get just a few things done.&lt;/p&gt;

&lt;p&gt;With Chalice, you are carefully guided through the process
of setting up your first microservice in Python. It comes out of
the box with sample code to do a &amp;ldquo;hello world&amp;rdquo; service, and
from that sample code the entire set of Lambda packaging
is built for you. There are a surprisingly large number of
moving parts to actually get a Lambda function running;
Chalice&amp;rsquo;s build system hides most of those from you at the start.&lt;/p&gt;

&lt;p&gt;The code is available on Github, either to run as-is,
to fork for your own edification, or simply to study.
I&amp;rsquo;ve gotten as far as hello, world, but no farther than that
yet. There are lots of warnings to the effect of &amp;ldquo;not
yet ready for production use!&amp;rdquo; so use with care.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AWS IoT to Node-RED</title>
      <link>http://vielmetti.github.io/post/2016/2016-10-11-aws-iot-to-node-red/</link>
      <pubDate>Tue, 11 Oct 2016 13:15:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-10-11-aws-iot-to-node-red/</guid>
      <description>&lt;p&gt;Duong Dinh Cuong (on Github as &lt;a href=&#34;https://github.com/cuongquay&#34;&gt;cuongquay&lt;/a&gt;) has contributed a node
for Node-RED that encapsulates the AWS IoT service and allows
straightforward communication between the two systems over MQTT.&lt;/p&gt;

&lt;p&gt;The node, node-red-contrib-aws-iot-hub,
includes support for the message-passing
part of AWS IoT using MQTT, allowing you to open
a channel to the IoT service and publish or subscribe
to message topics. The result is easy integration between
the two systems. As a part of this process, the node
includes support for AWS certificates that have to be
installed &amp;ldquo;just so&amp;rdquo; to allow AWS to trust Node-RED.&lt;/p&gt;

&lt;p&gt;The current release is 0.1.5 from today, October 11, 2016.
You can find it on &lt;a href=&#34;https://github.com/cuongquay/node-red-contrib-aws-iot&#34;&gt;Github&lt;/a&gt;,
on &lt;a href=&#34;https://www.npmjs.com/package/node-red-contrib-aws-iot-hub&#34;&gt;NPM&lt;/a&gt;,
and in the &lt;a href=&#34;http://flows.nodered.org/node/node-red-contrib-aws-iot-hub&#34;&gt;Node-RED flows library&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve tested this with my airplane tracking code which publishes
from a Raspberry Pi to AWS IoT using mosquitto, and it all seems
to check out OK. A next step on my part is to port the whole
experience up from my Mac where a test instance is running up to
CoreOS, and also to document the AWS command line to generate
the correct certificates in the correct format with the correct
file names.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Narrowband IoT (NB-IoT) as a low power cellular data protocol on the u-blox SARA-N2</title>
      <link>http://vielmetti.github.io/post/2016/2016-10-10-nb-iot/</link>
      <pubDate>Mon, 10 Oct 2016 16:15:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-10-10-nb-iot/</guid>
      <description>&lt;p&gt;In the process of looking at embedded radio components, I came across
the u-blox &lt;a href=&#34;https://www.u-blox.com/en/product/sara-n2&#34;&gt;SARA-N2&lt;/a&gt;, a low power
device designed to provide low bandwidth cellular data coverage for
Internet of Things devices - &amp;ldquo;low power consumption and extended coverage&amp;rdquo;
being the operative buzzwords. Speeds are 227 Kbps down and 21 Kbps up,
and it&amp;rsquo;s claimed to be &amp;ldquo;low power&amp;rdquo; though no specific power consumption
figures are provided.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s built on NB-IoT standards that are
&lt;a href=&#34;http://www.3gpp.org/news-events/3gpp-news/1785-nb_iot_complete&#34;&gt;standardized in June 2016&lt;/a&gt;
by the 3GPP project and which are codified in their Release 13.&lt;/p&gt;

&lt;p&gt;The first announcement of use of this system is by Telenor in Norway, using it
for a &lt;a href=&#34;http://www.mynewsdesk.com/uk/telenor/pressreleases/first-in-norway-with-narrowband-iot-1590130&#34;&gt;smart parking&lt;/a&gt;
demonstration application in the city of Trondheim.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The pilot commences in January 2017 and will test out how smart sensors can tell you where there is available parking, and in time make it possible to reserve a parking space on your mobile phone, obtain real-time information on when a space will be free and if necessary be guided to other parking spaces if it is full.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;No word yet on availability of dev boards for the SARA-N2. u-blox has been
good about getting some of their technologies into the DIY marketplace, with
the Particle Electron using their SARA‑G350, SARA‑U260 or SARA‑U270 chips,
and the Hologram Dash with the LISA-U200, SARA‑U260 or SARA‑U270 chips.
Still, u-blox&amp;rsquo;s product line is way bigger than the availability of
consumer-focused components to try them out.&lt;/p&gt;

&lt;p&gt;More NB-IoT news from &lt;a href=&#34;http://www.huawei.com/minisite/hwmbbf15/en/nb-iot-accelerating-cellular-iot.html&#34;&gt;Huawei&lt;/a&gt;
(from 2015), &lt;a href=&#34;http://www.vodafone.com/content/index/what/technology-blog/nb-iot-will-connect.html&#34;&gt;Vodafone&lt;/a&gt;
(indicating commerical rollout in 2017), and &lt;a href=&#34;http://www.gsma.com/connectedliving/narrow-band-internet-of-things-nb-iot/&#34;&gt;GSMA&lt;/a&gt;
(a vendor forum).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>sdr.hu and the emergence of lots of small wideband SDR receivers</title>
      <link>http://vielmetti.github.io/post/2016/2016-10-10-sdr-hu-small-public-sdr/</link>
      <pubDate>Mon, 10 Oct 2016 15:00:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2016/2016-10-10-sdr-hu-small-public-sdr/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://sdr.hu&#34;&gt;sdr.hu&lt;/a&gt; is the home base for OpenWebRX, a remote spectrum monitoring system
written by Andras HA7ILM.&lt;/p&gt;

&lt;p&gt;The system is designed to allow &lt;a href=&#34;https://github.com/simonyiszk/openwebrx&#34;&gt;OpenWebRX servers&lt;/a&gt;,
running on RTL-SDR or HackRF hardware, to share their radio spectrum and allow remote tuning
of the available radio bandwidth. A typical installation will allow up to four remote listeners
to independently tune in, and the tuning filters allow the listener to independently control
the bandwidth of the receiver.&lt;/p&gt;

&lt;p&gt;A sample display shows WMVP-AM in Chicago monitored from SE Michigan.&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Listening to the ALDS on ESPN 1000, WMVP-AM Chicago. Baseball (and radio DXing) instead of politics. &lt;a href=&#34;https://t.co/qFUMHDlqti&#34;&gt;pic.twitter.com/qFUMHDlqti&lt;/a&gt;&lt;/p&gt;&amp;mdash; Edward Vielmetti (@vielmetti) &lt;a href=&#34;https://twitter.com/vielmetti/status/785285239157370883&#34;&gt;October 10, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The wide band version of this is the &lt;a href=&#34;http://kiwisdr.com/KiwiSDR/&#34;&gt;KiwiSDR&lt;/a&gt;, a BeagleBone
based receiver which has been developed as a Kickstarter campaign. Look for those
systems on the sdr.hu list with a receiver tunable between 0 and 30 Mhz. This covers
all of the broadcast AM range plus shortwave broadcast and HF amateur bands.&lt;/p&gt;

&lt;p&gt;sdr.hu is not the only system with links to web-tunable SDR receivers. &lt;a href=&#34;http://websdr.org&#34;&gt;websdr.org&lt;/a&gt;,
hosted at U Twente in the Netherlands, has its own set of receiver software and hardware.
Coverage is by no means universal, but between the two collections there are hours of
DX listening ahead of you (including, for my purposes, lots of alternatives to pull in
baseball playoff broadcasts).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>