<!DOCTYPE html> 
<html>
<head> 
		<title>xml2json as part of a web parsing pipeline - Vacuum - Edward Vielmetti</title> 
	</head>
<body>


<h2>Vacuum weblog E. Vielmetti</h2>


<h3>
<a href="http://vielmetti.github.io/books/">books</a>
<a href="http://vielmetti.github.io/code/">code</a>
<a href="http://vielmetti.github.io/recipes/">recipes</a>
<a href="http://vielmetti.github.io/people/">people</a>
<a href="http://vielmetti.github.io/cities/">cities</a>
<a href="http://vielmetti.github.io/maps/">maps</a>
<a href="http://vielmetti.github.io/annarbor/">Ann Arbor</a>
<a href="http://vielmetti.github.io/categories/">categories</a>
<a href="http://vielmetti.github.io/keyphrases/">keyphrases</a>
</h3>




<h5>nature abhors a vacuum</h5>


<table>
<tr>
	

<td width="5%"></td>


<td width="30%" valign="top">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>Vacuum weblog from Edward Vielmetti</h1>
      <p class="lead">
       Tracking the comings and goings of @vielmetti 
      </p>
    </div>

    <h3><a href="http://vielmetti.github.io/">Home</a> </h3>
    <ul class="sidebar-nav">
      
        <li><a href="http://vielmetti.github.io/post/2015/2015-07-14-publishing-from-hugo-to-github-pages/"> Publishing from Hugo to Github Pages </a></li>
      
    </ul>

    <h3 class="panel-title">Recent Posts</h3> 
    <ul class="sidebar-recent">
	 
	<li><a href="http://vielmetti.github.io/post/2016/2016-04-24-facebook-break/" class="list-group-item">Taking a break from Facebook</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-04-23-roos-roast-downtown/" class="list-group-item">Roos Roast to add downtown Ann Arbor location</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-04-22-washtenaw-restaraunt-inspections/" class="list-group-item">Washtenaw restaurant inspections</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-04-22-prince/" class="list-group-item">Prince</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-04-22-milnor-time/" class="list-group-item">Milnor Time at Mr. Stadium</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-04-17-ecuador-terremoto/" class="list-group-item">Earthquake in Ecuador, April 16, 2016</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-04-06-reluctance/" class="list-group-item">Reluctance</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-04-06-yo/" class="list-group-item">Yo</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-03-30-upgrade-to-el-capitan/" class="list-group-item">Upgrade to El Capitan</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-02-14-stadium-boulevard-project/" class="list-group-item">Stadium Boulevard project bids high, portions of project to be delayed</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-02-14-chicken-and-onion-curry/" class="list-group-item">Chicken and onion curry</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-01-25-ann-arbor-public-schools-social-media-threat/" class="list-group-item">Ann Arbor Public Schools respond to social media threat</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-01-24-alaska-earthquake/" class="list-group-item">M7.1 earthquake felt in Anchorage, Alaska</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-01-22-writing-things-down/" class="list-group-item">Writing things down</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-01-22-a2b3-lunch-nonsummary/" class="list-group-item">a2b3 lunch non-summary for 3d week of January 2016</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-01-18-mlk-day-on-umich-campus/" class="list-group-item">Some highlights of MLK Day 2016 on the U of Michigan campus</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-01-17-qso-on-redditnet/" class="list-group-item">QSO on redditnet via Geekshed IRC</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-01-14-letterpress-qsl-cards/" class="list-group-item">Letterpress QSL cards</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-01-14-aprs-network-status/" class="list-group-item">Ann Arbor area APRS network status, January 2016</a></li>
         
	<li><a href="http://vielmetti.github.io/post/2016/2016-01-13-building-board-of-appeals-lacks-quorum-january-2016/" class="list-group-item">January 2016 Ann Arbor Building Board of Appeals lacks a quorum</a></li>
        
    </ul>

    <div class="sidebar-calendar">
	
    </div>

    <div class="sidebar-todo">
	
    </div>

    <div class="sidebar-blogroll">
	
    </div>

    <p>&copy; 2016. All rights reserved. </p>
  </div>
</div>

</td>


<td width="5%" valign="top"></td>


<td width="55%" valign="top" halign="right">
		<h3>10 September 2015</h3>
		<h1>xml2json as part of a web parsing pipeline</h1> 
		<p>The problem, simply put. You have a messy, real world HTML page;
you want to parse it to pull out some key element of it, to pass
along to some other task; you want that parsing pipeline to be
as compact as possible, because you&rsquo;re running on a small machine,
and you&rsquo;re doing the task frequently, and because the page may
change out from under you at any time.</p>

<p>Clearly this is not an optimal task to have, but you live with
the web you have, not with the web you want to have.</p>

<p>My approach to this task is to assemble a pipeline of Unix tools
that are as simple as possible, and that each do one thing pretty
well, and that in combination are all well-refined enough that there
are few surprises.</p>

<p><code>curl</code> is the workhorse for fetching pages. The invocation
<code>curl -m 15 -s http://example.com</code> pulls that page from the
net and feeds it to standard output, but times out after 15 seconds
so your pipeline doesn&rsquo;t completely fail if a remote site is down.</p>

<p><code>tidy</code> is the first thing I look at when doing data transformation.
<code>tidy -q -asxml 2&gt;/dev/null</code> takes HTML and converts it, quietly
and uncomplainingly, into XML. It&rsquo;s predictable and pretty fast.
<code>tidy</code> has been around since the dawn of the web, and it newly
has a <a href="https://github.com/htacg/tidy-html5">Github project</a> and
a <a href="http://www.html-tidy.org/">shiny web page</a> and a support
consortium, so if you want to build from source it&rsquo;s readily possible.</p>

<p>Given XML, convert it to JSON. Here there are quite a few choices,
depending on which language and which parser you want to start with,
and the dependency tree is deep. I am least satisfied with my alternatives
here, thus the motivation for this writeup. In alphabetical order by
language:</p>

<p>There is no POSIX standard <code>xml2json</code> command written in C, alas.</p>

<p>In C++ there&rsquo;s an <code>xml2json</code> command and library from Cheedoong Ch&rsquo;ng.
The <a href="https://github.com/Cheedoong/xml2json">Github project</a> says</p>

<blockquote>
<p>xml2json is the first carefully written C++ library that converts
XML document to JSON format. It&rsquo;s already been used in the soft
subtitle cross-domain solution at the server-end of Tencent Video
(<a href="http://v.qq.com">http://v.qq.com</a>) and its CDNs.</p>
</blockquote>

<p>In Dart, see Steve Hamblett&rsquo;s <code>xml2json.dart</code> library.
The <a href="https://github.com/shamblett/xml2json">Github project</a> includes
a set of unit tests, as well as explicit support for three
conventions (Parker, Badgerfish, and Google Data) for doing
the conversion. The test suites are welcomed.</p>

<p>In Go, see Darren Elwood (textnode)&rsquo;s <code>xml2json.go</code>. The
<a href="https://github.com/textnode/xml2json">Github project</a> includes
sample code to parse both RSS and generic XML files.</p>

<blockquote>
<p>Transform a stream of XML into a stream of JSON, without requiring
a schema or structs, written in Go (golang.org)</p>
</blockquote>

<p>In Node.JS, see <code>node-xml2json</code> from BugLabs which
converts XML to JSON using <code>node-expat</code>. You can install it
with <code>npm install xml2json</code>.</p>

<p>In Perl, see Isidro Vila Verde&rsquo;s <code>xml2json.pl</code>, which has a
<a href="https://github.com/jvverde/xml2json">Github project</a> and is based
on <code>XSLT</code>. &ldquo;You may need to install some perl modules before using it&rdquo;
is the extent of the install instructions.</p>

<p>In Python, see the <code>xmlutils</code> package from Kailash Nadh
and Yigal Lazarev. You can
install it with <code>pip install xmlutils</code>, or look at the
<a href="https://github.com/knadh/xmlutils.py">Github project</a>.</p>

<blockquote>
<p>xmlutils.py is a set of Python utilities for processing xml files
serially for converting them to various formats (SQL, CSV, JSON).
The scripts use ElementTree.iterparse() to iterate through nodes
in an XML document, thus not needing to load the entire DOM into
memory. The scripts can be used to churn through large XML files
(albeit taking long :P) without memory hiccups.</p>
</blockquote>

<p>Once the original HTML document emerges nicely formatted as JSON,
it&rsquo;s relatively easy to pick out elements from it in most cases.
Two tools to do this are <code>jq</code> and <code>jp</code>.</p>

<p><code>jq</code>, from Stephen Dolan, is a command-line JSON processor. Now
at version 1.5, it has a <a href="https://stedolan.github.io/jq/">web site</a>
and a <a href="https://github.com/stedolan/jq">Github repository</a>, plus
a handy <a href="https://jqplay.org/">online test site</a> that lets you
do interactive tests. It&rsquo;s written in portable C.</p>

<blockquote>
<p>jq is like sed for JSON data - you can use it to slice and filter
and map and transform structured data with the same ease that sed,
awk, grep and friends let you play with text.</p>
</blockquote>

<p><code>jp</code>, from James Saryerwinnie, is a command line version of the JMESPath
query language for JSON, documented at <a href="http://jmespath.org/">http://jmespath.org/</a> . This
is the same query language embedded into the Amazon Web Services
command line (AWS CLI), and it has powerful and compact operators
for extracting elements from a JSON document. There are libraries
in Python, PHP, Javascript, Ruby, Lua, and Go that implement JMESPath.
<code>jp</code> is written in Go, and has cross-development tools available.</p>

<hr/>

<p>So that&rsquo;s the environment. It&rsquo;s a bit of a pain to get all of
those tools running on a new bare-metal machine, so my thought
is to put everything into one Docker build and make it straightforward
to wrap everything together. Ideally this will be a fairly
minimalist build, and thus the challenge is to find the set
of dependencies that is small enough.</p>
 
</td>


<td width="5%" valign="top"></td>

</tr>
</table>


<h3>Notes afterwards</h3>
	<p>
	Recreating more or less my original layout, but with 
	dynamically loaded content. I guess that could work!
	</p>
	<p>
<a title="Real Time Analytics" href="http://clicky.com/100880293"><img alt="Real Time Analytics" src="//static.getclicky.com/media/links/badge.gif" border="0" /></a>
<script src="//static.getclicky.com/js" type="text/javascript"></script>
<script type="text/javascript">try{ clicky.init(100880293); }catch(e){}</script>
<noscript><p><img alt="Clicky" width="1" height="1" src="//in.getclicky.com/100880293ns.gif" /></p></noscript>
</p>

</body>
</html> 
