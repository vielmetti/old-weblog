<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jeroen Janssens on tracker</title>
    <link>http://vielmetti.github.io/people/jeroen-janssens/</link>
    <description>Recent content in Jeroen Janssens on tracker</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 28 Feb 2015 16:19:10 -0400</lastBuildDate>
    <atom:link href="http://vielmetti.github.io/people/jeroen-janssens/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>R, me hearties</title>
      <link>http://vielmetti.github.io/post/2015/2015-02-28-r-me-hearties/</link>
      <pubDate>Sat, 28 Feb 2015 16:19:10 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-02-28-r-me-hearties/</guid>
      <description>&lt;p&gt;I&#39;ve been fond of maps and graphs for a long time, but haven&#39;t had a good set 
of tools to play with that easily generate decent versions of same from various
data sets I&#39;ve found or accumulated.&lt;/p&gt;

&lt;p&gt;The small hope is that a little bit of hacking on the right tools will fix this.&lt;/p&gt;

&lt;p&gt;One of the tools of choice is R, a language for statistics and data analysis. It&#39;s tremendously powerful and a bit complicated, but I&#39;m not trying to learn the whole thing; rather, I&#39;m after just the barest minimum so that I can competently generate a scatterplot of data and place it onto a map.&lt;/p&gt;

&lt;p&gt;I&#39;m working through the examples on Zev Ross&#39;s &lt;a href=&#34;http://zevross.com/blog/2014/07/16/mapping-in-r-using-the-ggplot2-package/&#34;&gt;Mapping in R using the ggplot2 package&lt;/a&gt;, which looks like about the right level of detail to start from. The other useful and helpful information that I&#39;m bootstrapping from is Jeroen Janssens &lt;a href=&#34;http://datascienceatthecommandline.com/&#34;&gt;Data Science at the Command Line&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The first production of this is just a scatterplot; it&#39;s based on Ann Arbor Downtown Development Authority parking data.&lt;/p&gt;

&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;en&#34;&gt;&lt;p&gt;Learning R. Plotting the biggest dataset I have handy (parking data). See the garage fills up, empty out again &lt;a href=&#34;http://t.co/GBnrpXGKWU&#34;&gt;pic.twitter.com/GBnrpXGKWU&lt;/a&gt;&lt;/p&gt;&amp;mdash; Edward Vielmetti (@vielmetti) &lt;a href=&#34;https://twitter.com/vielmetti/status/571424329499615232&#34;&gt;February 27, 2015&lt;/a&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>using &#34;jq&#34; for command line web applications for civic data</title>
      <link>http://vielmetti.github.io/post/2014/2014-10-05-using-jq-for-command-line-web-applications-for-civic-data/</link>
      <pubDate>Sun, 05 Oct 2014 09:03:34 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2014/2014-10-05-using-jq-for-command-line-web-applications-for-civic-data/</guid>
      <description>&lt;p&gt;One of the tools that I rediscovered and have been really happy for
having done so is &amp;ldquo;jq&amp;rdquo;, a command line tool that bills itself as
&amp;ldquo;awk for json&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been writing awk code since 1985, and some limited subset
of it is something that I know really, really well. awk, however,
is from the punchcard era, and as such it likes to deal with records
that are all on one line each. Parsing JSON in awk is very clumsy
and ad hoc and really doesn&amp;rsquo;t work all that well. Since most Internet
APIs these days have some kind of JSON encoding, it means that you
can&amp;rsquo;t simply dash off an awk one-liner to consume and transform
Internet input data.&lt;/p&gt;

&lt;p&gt;jq fixes that situation. Here for example is a one line renderings of a common task I look to solve with municipal data as a test of any new tool development: analysis of parking data. This code sample prints the total number of open spaces in the Ann Arbor Downtown Development Authority&amp;rsquo;s garages:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;curl -s http://www.a2dda.org/map/AADDACount.json |
  jq &#34;[.countdata[].spacesavail | tonumber] | add&#34; &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&amp;rsquo;m not going to try to explain how jq works, except to note that
it&amp;rsquo;s constructed in order to be a filter: data comes in one JSON
object at a time, and the script iterates over them, transforming
them in some way and then passing JSON out the other end. This makes
it perfect for ad hoc Unix pipeline efforts where you&amp;rsquo;re chipping
away at a data set trying to make sense of it by successively
refining it as you go.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve built jq pipelines for this Ann Arbor parking data, for AAATA
bus system data, and for the Marquette Park Cemetery data. The
parking data is straightforward, since it exits the system as JSON.
Bus system data is only incrementally harder; it started either as
HTML or as XML, and for that you want to use &amp;ldquo;tidy&amp;rdquo; and &amp;ldquo;xml2json&amp;rdquo;
in your pipeline. The Park Cemetery data set started as JSON via
the Socrata SODA API, but I needed little bits of &amp;ldquo;sed&amp;rdquo; and &amp;ldquo;perl&amp;rdquo;
to smooth out some rough edges in the source data; it really wants
to end up as GeoJSON when I&amp;rsquo;m done, but it isn&amp;rsquo;t there quite yet.&lt;/p&gt;

&lt;p&gt;Shell programming is my favorite programming environment. Any time
I can take a set of well-understood tools and crunch through big
data sets with only a few lines of code, I&amp;rsquo;m happy. The challenge
of shell programming is that it&amp;rsquo;s full of opportunities to get
things just a little bit wrong with parsing; by making JSON the
data format that&amp;rsquo;s shoveled between programs rather than a flat
one-record-per-line text format, you open up the opportunity for
pulling apart rather complex structures and manipulating them with
hardly any work.&lt;/p&gt;

&lt;p&gt;For further reading, see Jeroen Janssens new book &lt;a
href=&#34;http://datascienceatthecommandline.com/&#34;&gt;Data Science at the
Command Line&lt;/a&gt; which works you way through dozens of tools like
this that can help manage big data without big programs.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>