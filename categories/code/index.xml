<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Code on tracker</title>
    <link>http://vielmetti.github.io/categories/code/</link>
    <description>Recent content in Code on tracker</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Jul 2015 10:05:00 -0400</lastBuildDate>
    <atom:link href="http://vielmetti.github.io/categories/code/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Daily Coffee and Wifi, Roos Roast Wednesday edition</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-22-daily-coffee-wifi-roos-roast/</link>
      <pubDate>Wed, 22 Jul 2015 10:05:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-22-daily-coffee-wifi-roos-roast/</guid>
      <description>&lt;p&gt;At Roos, an espresso over ice with a little half and half and a hard
boiled egg. It&amp;rsquo;s a very compact breakfast. The espresso is served in
an appropriately sized glass mug and tastes like the strongest little
iced latte you will ever have.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;On my Mac, run &amp;lsquo;boot2docker upgrade&amp;rsquo;. That gets me up to current 1.7.1
revision of everything.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Edwards-MacBook-Air:~ emv$ docker version
Client version: 1.7.1
Client API version: 1.19
Go version (client): go1.4.2
Git commit (client): 786b29d
OS/Arch (client): darwin/amd64
Server version: 1.7.1
Server API version: 1.19
Go version (server): go1.4.2
Git commit (server): 786b29d
OS/Arch (server): linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The issue that 1.7.1 resolves for me is certificate support - if I
understand the bug right, the Docker daemon was creating a key for
each interface it had, but not all of the interfaces were up at key
init time. The fix was to move DHCP init earlier in the start sequence
so that everything was initialized by the time key creation took place.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;The Docker team is trying to improve code quality by having their
code base pass the &lt;code&gt;golint&lt;/code&gt; test. The open issue,
&lt;a href=&#34;https://github.com/docker/docker/pull/14784&#34;&gt;fix golint errors/warnings #14784&lt;/a&gt;,
has attracted a swarm of contributors, and a lot of them have
proposed changes that don&amp;rsquo;t pass the automated tests. The build
farm is managed with Jenkins, and you can see the
&lt;a href=&#34;https://jenkins.dockerproject.org/&#34;&gt;status of every build of Docker&lt;/a&gt; on their
dashboard.&lt;/p&gt;

&lt;p&gt;Having a full lintable codebase is a great goal. The challenge comes when
the suggested changes by lint send you in the direction of making an
incompatible change to some interface that has the &amp;ldquo;wrong&amp;rdquo; name but that
people were relying on.&lt;/p&gt;

&lt;p&gt;Perhaps importantly for the work I&amp;rsquo;m doing it&amp;rsquo;s worth noting that currently
all of these tests are done on x86 platforms (Linux and Windows) and there
isn&amp;rsquo;t an official automated build on ARM. I&amp;rsquo;ve been using the
&lt;a href=&#34;http://blog.hypriot.com/downloads/&#34;&gt;Docker distribution from Hypriot&lt;/a&gt; as my
baseline for working on the Raspberry Pi, with good success.&lt;/p&gt;

&lt;hr/&gt;
</description>
    </item>
    
    <item>
      <title>bocker is a subset of Docker in 100 lines of shell script</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-21-docker-in-bash/</link>
      <pubDate>Tue, 21 Jul 2015 18:48:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-21-docker-in-bash/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/p8952/bocker&#34;&gt;bocker&lt;/a&gt; is Docker (or at least
a good sized subset of it) in 100 lines of shell script.
I suppose the point is that even though there&amp;rsquo;s a huge
world of hype surrounding containerization as a next step
of systems management, when you get down to it, it&amp;rsquo;s just not
that complicated.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Coworking notes at Elixir Vitae</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-21-coworking-notes/</link>
      <pubDate>Tue, 21 Jul 2015 16:57:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-21-coworking-notes/</guid>
      <description>&lt;p&gt;A productive afternoon with Mohan Kartha in which I opened a great
many tabs in Chrome. This bit of writing to close those out. Elixir
Vitae is a great spot for writing - lots of quiet noise from the coolers
to keep a background hum, and close to the bus station.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;I&amp;rsquo;m sorting out the simplest task that I&amp;rsquo;d like to do with Node-RED,
now that I have a Raspberry Pi 2 running it under Docker in a configuration
that&amp;rsquo;s reliable enough that it seems like it&amp;rsquo;s stable. The easiest
network test in the world is the ping test, and so my first stab at
a try for &amp;ldquo;run always&amp;rdquo; is a simple configuration to notice when the
network looks like it&amp;rsquo;s down and when it is to collect some more
detailed information and log it to a file.&lt;/p&gt;

&lt;p&gt;The inspiration for that is this simple configuration from an idea
by Nathan Chantrell, implemented by Martin Harizanov in 2014.
&lt;a href=&#34;https://harizanov.com/2014/03/presence-detection-using-phones-wifi-and-node-red/&#34;&gt;Presence detection using phone’s WiFi and Node-RED&lt;/a&gt; relies on static
IP address assignments from DHCP, plus &amp;ldquo;ping&amp;rdquo;, to notice if
someone&amp;rsquo;s device is in the building, turned on, and listening to
wifi.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve had enough phones drain their battery to know that absence
of a wifi signal is not an unambiguous marker!&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;Fantelope is doing a beta product launch at the final AFC Ann Arbor minor
league soccer game of the year, Saturday, July 25 at 6 PM at Hollway
Field (Pioneer High School, 601 W. Stadium, Ann Arbor). See
&lt;a href=&#34;http://fantelope.com/afc-ann-arbor-fantelope-beta-launch/&#34;&gt;the Fantelope web site&lt;/a&gt;
for more details.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;My first pass at writing code to send postcards from Lob.com is
working. The note to self is that if you have a square bracket in
a URL, that you have to turn off curl&amp;rsquo;s globbing function, e.g.
with -g or &amp;ndash;globoff. &amp;ldquo;When you set this option, you can specify
URLs that contain the letters {}[] without having them being
interpreted by curl itself. &amp;ldquo;&lt;/p&gt;

&lt;p&gt;Every card has a tracking code, so the next bit of reporting to write
is to see which cards are awaiting printing, which ones are in transit,
where they are going to and whether they have been received.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;The AAATA moved the endpoint URL for its old-school &amp;ldquo;classic&amp;rdquo;
mobile RideTrak application. To go to a particular route like
the 5, see e.g. &lt;a href=&#34;http://mobile.theride.org/classic/rideguide_m.asp?route=5&#34;&gt;http://mobile.theride.org/classic/rideguide_m.asp?route=5&lt;/a&gt; .
The main &lt;a href=&#34;http://mobile.theride.org&#34;&gt;http://mobile.theride.org&lt;/a&gt; has a newer interface, but
alas my Windows Phone 8.1 with its Internet Explorer browser
doesn&amp;rsquo;t do that page justice. (That, and I prefer the old interface
because I managed to figure it out for the stop I&amp;rsquo;m always catching
the bus from.)&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;&lt;a href=&#34;http://www.getlittlebird.com/&#34;&gt;Little Bird&lt;/a&gt; promises to
&amp;ldquo;help businesses unlock the valuable information in structured social data&amp;rdquo;.
I&amp;rsquo;ve asked for a trial to see what they have in store.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;I&amp;rsquo;m wondering what the best approach is to the task of
&amp;ldquo;download all of my email from Gmail&amp;rdquo;, since the storage I
now have available on my laptop would make it straightforward
to have an 18 GB personal mail spool and because I really actually
would love to search through it so that I can mark some messages
for permanent deletion. One possibility is &lt;a href=&#34;https://www.enkive.org&#34;&gt;Enkive&lt;/a&gt;
from The Linux Box.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;I am reminded that I want to carry around a set of headphones with me
that plug into my Nokia 635 so that I can use the phone as a radio,
and also reminded that I want to try to construct a headphone dipole
as an antenna for my NooElec DVB-T tuner. The challenge will be remembering
those desires at the right time so that when I see the parts I need
in the junk pile at home that I can grab what I need for my every
day carry bag.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;Oh, and I need to track down an 8 GB USB stick to load a boot ISO on.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Daily coffee and wifi, ERC South Main</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-21-daily-coffee-wifi-erc-south-main/</link>
      <pubDate>Tue, 21 Jul 2015 10:30:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-21-daily-coffee-wifi-erc-south-main/</guid>
      <description>&lt;p&gt;Espresso over ice at ERC South Main. This is now my favorite summer drink.
Served in a cup with enough ice and you get the makings of a very strong
iced latte, just add a little half and half.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The work of the morning is finishing up yesterday&amp;rsquo;s work on sending
postcards with Lob.com. Key to this effort is resizing your favorite
images so that they meet the template. Fortunately I had the presence
of mind seven years ago to
&lt;a href=&#34;http://vielmetti.github.io/post/2008/2008-12-29-image-processing-on-the-mac-with-sips-imagemagick-watching-dte-restore-power-slowly/&#34;&gt;write up my notes on using sips and Imagemagick&lt;/a&gt;
for image manipulation and that helped. In this case the magic incantation
was&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sips -z 1275 1875 original.jpg --out new.jpg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you don&amp;rsquo;t have a Mac, or want to do this on a server or container
somewhere, you&amp;rsquo;ll want Imagemagick. That venerable program has a
bazillion options, and you&amp;rsquo;ll find the image geometry options at
&lt;a href=&#34;http://www.imagemagick.org/script/command-line-processing.php#geometry&#34;&gt;http://www.imagemagick.org/script/command-line-processing.php#geometry&lt;/a&gt; .
Recreating this exact sips command is left as an exercise for the reader.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;That bit of image processing taken care of, the next iteration is to
launch a few actual postcards into the ether. After having confirmed
that everything goes OK on the test key, I sent out four cards. Estimated
delivery date is July 30, so I&amp;rsquo;m expecting about a two week turnaround
for feedback that I got everything right. Lob has card tracking so I guess
the next step is to write the simple tools to know when things were
delivered so that I can plan some phone calls.&lt;/p&gt;

&lt;hr  /&gt;

&lt;p&gt;My cousin Zorba has perhaps the best bio in the business.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;He has, in the course of his endeavors: been shot at by Navajos
in Utah; seized and threatened at knifepoint by rednecks in Arkansas;
chased by AK-47-toting soldiers in Hungary; run out of town by the
Penitentes in Truchas; shaken down by the Federales in Baja, and
forced to be rude to secure a cab in Rome. He has hung out of and
over: planes, balloons, helicopters, boats, rafts, race cars,
elevator shafts, too tall cliffs, and real deep canyons- and yet,
he still has enthusiasm and a good attitude.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;Jerry Davis asks why we still have academic journals:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The Web has greatly reduced the barriers to entry for new journals
and other platforms for communicating scientific output, and the
number of journals continues to multiply. This leaves readers and
authors with the daunting cognitive challenge of navigating the
literature and discerning contributions that are both relevant and
significant. Meanwhile, measures of journal impact that might guide
the use of the literature have become more visible and consequential,
leading to “impact gamesmanship” that renders the measures increasingly
suspect.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The essay, published in &lt;a href=&#34;http://asq.sagepub.com/content/59/2/193&#34;&gt;Administrative Science Quarterly&lt;/a&gt; in June 2014, has the seeds of its own answer. Journals
exist to enrich academic publishers.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Pay per Article - You may purchase this article for US$32.00. You
must download your purchase, which is yours to keep, within 24
hours.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&amp;rsquo;ll just ask Jerry for a preprint.&lt;/p&gt;

&lt;p&gt;Previously (1995!) I get quoted in the Times Higher Education Supplement.
The debate then centered around Stevan Harnad, an open access journal
advocate who saw clearly the trend towards low cost electronic publications,
thusly:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It remains only to tally up these PostGutenberg values: If the
world&amp;rsquo;s esoteric scholarly/scientific literature were available to
everyone for free in electronic form, the first benefit to the
author would be the great increase in the visibility, accessibility
and hence the potential impact of his work (1). This would of course
also be a benefit to all scholars when they are wearing their
readers&amp;rsquo; rather than their authors&amp;rsquo; hats (2). Some fear that such
a literature would be overwhelming and un-navigable, but stop and
think: How do we currently manage it in paper? If the entire corpus
were transferred to the Net, instead of our eyes and fingers and
feet doing the walking to get to the papers or to get the papers
to us, electronic directories containing everything could be searched
using the kinds of keyword search already used today in searching
electronic databases that contain the titles and abstracts (but not
the articles) in the paper literature. Then, one more click, and
you have the paper itself! Or clever &amp;ldquo;knowbots&amp;rdquo; (automatic search
programmes) could be designed to go out instead of us and look for
papers fitting our profile of interests, leaving us even more time
to actually read what we want and to do our research, rather than
running after the literature.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My reply, &lt;a href=&#34;https://www.timeshighereducation.co.uk/features/harnad-versus-fuller-round-2/98502.article&#34;&gt;immortalized from the past&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Edward Vielmetti (bottom) uncontroversially points out that there
is a lot of rubbish on the Internet; but he is sceptical of peer
review as a solution.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The original commentary is lost in the mists of time, I hope.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;There are two institutions that went by the name of GopherCon.
(No, it&amp;rsquo;s not a furry convention; that&amp;rsquo;s Anthrocon.) One was
from the early 1990s surrounding the Gopher internet browsing
protocol; the other is for enthusiasts and programmers of the
Go programming language. I am not aware of anyone who can claim
to have gone to both events.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.databaseteam.org/10-database/0722cf77b51ab4ba.htm&#34;&gt;GopherCon 1995&lt;/a&gt;
featured discussion of GopherVR and VRML for virtual reality in Gopher,
the Hyper-G Information System for hypertext authoring, and an
early morning session on Integrating Gopher and WWW.&lt;/p&gt;

&lt;p&gt;GopherCon 2015 was in early July in Colorado. Of the items on
the agenda this talk by Barak Michener was perhaps the most interesting
to follow through on:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Written in Go, Cayley is a graph database based on technology
behind Freebase.com. Starting with a short history of the inspirations
behind Cayley, this talk will deep-dive into the moving parts of
building a graph database, between the various query languages, the
storage engines, and the iterator trees.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And of course this blog is now powered by Hugo which is written in Go
so I&amp;rsquo;m learning a little about the Go template language as a side effect.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Daily coffee and wifi at Biggby Packard</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-20-daily-coffee-wifi-packard-biggby/</link>
      <pubDate>Mon, 20 Jul 2015 11:13:43 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-20-daily-coffee-wifi-packard-biggby/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s a warm but pleasant mid-summer late Monday morning, and I&amp;rsquo;m
visiting the first cafe inbound on a walk to town. Biggby Packard
is where I end up when the inbound bus schedule timing is just so.&lt;/p&gt;

&lt;p&gt;Summertime cafes near campus are odd. There&amp;rsquo;s not really enough here
to motivate someone to drive here for coffee, so it draws people
from the surrounding neighborhood and from the athletic campus.
I&amp;rsquo;ve been in here before when I was the only patron for more than
an hour but this morning there&amp;rsquo;s a few more people sitting typing.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;I first ran into the &amp;ldquo;pocketmod&amp;rdquo; planning technique in 2005, and
here it is 10 years later and there&amp;rsquo;s one in my pocket.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A pocketmod is a cleverly folded piece of paper with preprinted
templates for things like a mini calendar, todo list, quadrille
paper, checklist etc. It&amp;rsquo;s the smallest instance of a PDA that I
have seen yet, requiring nothing more than a blank piece of paper
and a pair of scissors to execute. You could even bypass the scissors
if you had good paper and a crisp straightedge to do a rip.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Astoundingly, &lt;a href=&#34;http://www.pocketmod.com/&#34;&gt;http://www.pocketmod.com/&lt;/a&gt; is still online, in all of
its 2005-2007 glory. That system does an 8-up PDF from a set of templates,
so that you can print a lovingly detailed mini booklet. My own use
has long since devolved into scrap paper plus rip down the center.
When it fills up, invert the fold, and you have a brand new organizer.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;Now playing, Johnny Cash&amp;rsquo;s &amp;ldquo;One Piece at a Time&amp;rdquo;. &amp;ldquo;GM wouldn&amp;rsquo;t miss just
one little piece.&amp;rdquo; Look for the promo photo.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;Menu plan: green beans with walnuts and miso sauce, plus a few green beans
uncooked on the side for J who likes to eat the raw. A recipe of sorts is
at &lt;a href=&#34;http://www.thekitchn.com/recipe-review-green-beans-with-49874&#34;&gt;The Kitchn&lt;/a&gt;,
which refers to a 2005 New York Times Dining article about Yumiko
Kano and her brand of Japanese cooking.
&lt;a href=&#34;http://justbento.com/handbook/bento-basics/review-saisai-lunch-vegan-bento-by-yumiko-kano&#34;&gt;Just Bento&lt;/a&gt; has some reviews of books by Yumiko Kano (aka Yumiko Kanoh or
Kanou Kumiko). &lt;a href=&#34;http://theunbearablelightnessofbeinghungry.com/2009/10/vegetarian-ramen/&#34;&gt;The Unbearable Lightness of Being Hungry&lt;/a&gt; has a 2009 vegetarian ramen recipe
from the same author. There&amp;rsquo;s a &lt;a href=&#34;http://metropolis.co.jp/dining/table-talk/yumiko-kano/&#34;&gt;profile of Yumiko Kano&lt;/a&gt; in Metropolis.&lt;/p&gt;

&lt;p&gt;We got some
very yummy new potatoes from Farmers Market that I cooked up last night,
which were 1000x more wonderful than storebought old potatoes.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;Exit Biggby heading north to North Campus to Mujo&amp;rsquo;s, for some
time spent writing. Close all of the windows, save all of the
documents, publish locally all of the works in progress. North
Campus has the virute of frequent free bus service from Central
Campus, and it&amp;rsquo;s far enough away to completely flush all of
the thoughts of what I had been doing so I can work on another project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>lob a postcard: printer sends cards via API</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-19-lob-a-postcard-printer/</link>
      <pubDate>Sun, 19 Jul 2015 22:05:18 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-19-lob-a-postcard-printer/</guid>
      <description>&lt;p&gt;Lob.com has an API to send postcards-as-a-service ($0.70 per each,
full custom both sides). Details at &lt;a href=&#34;https://lob.com/services/postcards&#34;&gt;https://lob.com/services/postcards&lt;/a&gt; .
It works, but all of the user interface is up to you; if you know
a good service for delivering a single full-custom postcard with
postage that actually has a user interface and not an API for less
than $1.00 each, let me know and I&amp;rsquo;ll update here.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve started checking in a few tiny utility programs that exercise
the Lob API. Look for &lt;a href=&#34;https://github.com/vielmetti/postcard&#34;&gt;https://github.com/vielmetti/postcard&lt;/a&gt; on Github.
The goal at some point is to have a &amp;ldquo;postcard&amp;rdquo; application
that has a user interface like so.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;postcard --to mom --photo cute-kids.jpg --message &amp;quot;they get so big so fast! love ed&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also in this business is PostalMethods with a Postcard API based on SOAP.
That&amp;rsquo;s not a convenient interface in the languages that I use, but you
can look at the API at &lt;a href=&#34;http://www.postalmethods.com/lp/postcard-api&#34;&gt;http://www.postalmethods.com/lp/postcard-api&lt;/a&gt; .
Their prices for postcards run $1.50 per each or less, with quantity
discounts - see &lt;a href=&#34;http://www.postalmethods.com/pricing&#34;&gt;http://www.postalmethods.com/pricing&lt;/a&gt; for details.&lt;/p&gt;

&lt;p&gt;Postful used to have an API for postcards. They were
&lt;a href=&#34;http://blog.click2mail.com/articles/view/click2mail-acquires-postful/&#34;&gt;bought by Click2Mail in 2011&lt;/a&gt;. Pricing for Click2Mail&amp;rsquo;s postcards starts at $0.25
per card plus $0.284 postcard, but there&amp;rsquo;s a $2.00 minimum if
you don&amp;rsquo;t have credits on account. I wasn&amp;rsquo;t able to determine
at first glance whether their REST API applied to onesy-twoesy
printing options, though it was clear that if you wanted to send
1000 cards that the pricing would be competitive.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Levenshtein distance for approximate match</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-17-levenshtein-distance-for-approximate-match/</link>
      <pubDate>Fri, 17 Jul 2015 16:11:41 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-17-levenshtein-distance-for-approximate-match/</guid>
      <description>&lt;p&gt;The problem, simply stated, is that of typoes and inconsistent
spelling and pluraliziation. Let&amp;rsquo;s say you have a collection of
text that you want to annotate with some metadata, like categories
and tags. You don&amp;rsquo;t want to set aside ahead of time exactly which
tags you want to use, but you want to catch through some test or
lint step that you&amp;rsquo;ve done something wrong by typing &amp;ldquo;apples&amp;rdquo; into
a field that really has &amp;ldquo;apple&amp;rdquo; most of the time. A good algorithm
will catch minor deviations from the norm and advise you when you
should go back with a fresh pair of eyes and do an edit.
The bigger problem is
deduplication
.&lt;/p&gt;

&lt;p&gt;My first pass at a proposed solution was to look for a version of
the old Unix program &amp;ldquo;uniq&amp;rdquo; that would have an approximate match.
There is also an old Unix program &amp;ldquo;agrep&amp;rdquo; (&amp;ldquo;approximate grep&amp;rdquo;) from
Udi Manber.&lt;/p&gt;

&lt;p&gt;[WM92a]
Wu S. and U. Manber, &amp;ldquo;Agrep - A Fast Approximate Pattern-Matching
Tool,&amp;rdquo; Usenix Winter 1992 Technical Conference, San Francisco (January
1992), pp. 153-162.&lt;/p&gt;

&lt;p&gt;Neither of these first lines of attack to see if someone had
completely solved the problem before did the trick, but some
searching around and a conversation with
John Hritz

hit the neuron that remembered the algorithm called the
Levenshtein distance
.
That led me to
Wikibook: Algorithm Implementation
,
and its set of
&lt;a href=&#34;https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance&#34;&gt;Levenshtein distance code&lt;/a&gt;. It so happened that there
was a very slow implementation in the bash shell included
in that collection that was a cut and paste and two lines of
code from being exactly what I needed. A little bit of glue
code in awk and I was ready to go.&lt;/p&gt;

&lt;p&gt;Now the problem with cut and paste two lines of code is that this
particular implmentation is very slow, albeit correct. Given the
choice between slow correct code and fast code that&amp;rsquo;s wrong (because
of the bug that you don&amp;rsquo;t yet understand), I&amp;rsquo;ll take the slow code
plus a comment and a writeup that describes how to make it faster.&lt;/p&gt;

&lt;p&gt;What I&amp;rsquo;m really after is just the pairwise comparison of a set
of words where the two words are close to each other. If the
distance between two words is greater than some threshhold, I don&amp;rsquo;t need
to go any further. That algorithmic shortcut isn&amp;rsquo;t in the library
codes that I found.&lt;/p&gt;

&lt;p&gt;The bigger question is how to write a
checklist
and implement it in code to make sure that a big body of work stays
internally consistent. It&amp;rsquo;s one thing to have a
categorization
rule for your writers that says &amp;ldquo;always use the
singular&amp;rdquo;, but very much something different to have Test 38 in
your automated test corpus apply that rule and notice when it&amp;rsquo;s
wrong.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using a squid cache to make automated data collection a bit less rude</title>
      <link>http://vielmetti.github.io/post/2015/2015-06-28-using-a-squid-cache-to-make-automated-data-collection-a-bit-less-rude/</link>
      <pubDate>Sun, 28 Jun 2015 15:23:26 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-06-28-using-a-squid-cache-to-make-automated-data-collection-a-bit-less-rude/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.squid-cache.org/&#34;&gt;&lt;code&gt;squid&lt;/code&gt; is a web caching system&lt;/a&gt;. Instead of browsing directly to a site, you point your browser at a squid cache, and the cache serves up cached copies of the data you are asking for. If squid has an out of date copy of the data it fetches a new one for you. The goal is to be a transparent cache, and to be nearly as fast as direct access when you don&#39;t have the data, and way faster when you do.&lt;/p&gt;

&lt;p&gt;I&#39;m doing some automated data collection from the web using &lt;code&gt;curl&lt;/code&gt;, and as a part of that I want to not be overly aggressive in harvesting details from a site if I already have a recent copy of the data that hasn&#39;t changed. Putting a cache in the way makes sense, since unlike most GUI based browsers that have their own caches, &lt;code&gt;curl&lt;/code&gt; just fetches whatever it&#39;s asked for unquestioningly even if it just got the same thing seconds ago - unless you tell it to use a cache.&lt;/p&gt;

&lt;p&gt;The first appearance of squid dates to 1996, so it&#39;s old software by modern standards. It dates from the bad old days when the Internet was slow on long haul links but fast locally, and so it made all the sense in the world to optimize and economize. Even now there are lots of times and places where the net is slow enough that you&#39;re willing to introduce a little bit of complexity in exchange for a little bit of speed.&lt;/p&gt;

&lt;p&gt;I installed my copy of squid on my Mac using MacPorts, which seems to do a fine job. I had also tried to build a copy of squid using what looked like simple instructions on Docker using the configuration on &lt;a href=&#34;https://github.com/michaljemala/docker-squid&#34;&gt;@michaeljemala/docker-squid&lt;/a&gt;, but for reasons as of yet unexplained I got the error message&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
curl: (7) Failed to connect to localhost port 3128: Connection refused
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;after setting that up and following package directions.  Still puzzling out whether that&#39;s a result of some Docker configuration oddness on 1.7.0, or something else. Anyway, the native version is working, so I&#39;m good for now.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using GNU Parallel to speed up network operations</title>
      <link>http://vielmetti.github.io/post/2015/2015-06-24-using-gnu-parallel-to-speed-up-network-operations/</link>
      <pubDate>Wed, 24 Jun 2015 10:23:20 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-06-24-using-gnu-parallel-to-speed-up-network-operations/</guid>
      <description>&lt;p&gt;My current laptop (a MacBook Air) has a plenty fast processor and super fast disk. This means that the usual bottleneck for system operations is the network, not the computer itself. I go from wifi spot to other wifi spot enough that I know that performance varies a lot, and especially there are a lot of places where the network is really not fast enough.&lt;/p&gt;

&lt;p&gt;Enter GNU Parallel. This little tool lets you spawn a whole series of processes, with the next one starting when the previous one completes. If you are working on something where it doesn&#39;t matter which order things happen in as long as they all get done you are in good shape to get tremendous performance improvements simply by overlapping operations.&lt;/p&gt;

&lt;p&gt;An example:&lt;/p&gt;

&lt;p&gt;DTE Energy does not have one single page on their web site that shows you the total number of outages across their system - or if they do have it, it&#39;s so well hidden that I haven&#39;t found it. What they do have is a way to fetch the outage count for a single ZIP code. So, armed with a set of zip codes, you can determine a total. You don&#39;t care which ZIP is fetched first but you do want them all to show up before you add them up.&lt;/p&gt;

&lt;p&gt;The one-line command I have for this is&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
parallel -P 32 -a ~/data/dte-zips ~/bin/dte-by-zip | jq -s add
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The script dte-by-zip runs as follows, fetching a page from a DTE server and parsing it:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ dte-by-zip 48104&lt;/p&gt;
  
  &lt;p&gt;38&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;thus the parallel invocation reads roughly as follows: &#34;for 32 parallel threads, using the dte-zips data file one line a time as command line arguments, run dte-by-zip; add up all the results&#34;.&lt;/p&gt;

&lt;p&gt;Note that if you are using &#34;curl&#34; to fetch pages, you want to be aware of the &lt;code&gt;--max-time&lt;/code&gt; option.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;-m, --max-time &lt;seconds&gt;
               Maximum time in seconds that you allow the  whole  operation  to
               take.   This is useful for preventing your batch jobs from hang-
               ing for hours due to slow networks or links going  down. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now you don&#39;t want to go too crazy with parallel operations on network resources, it&#39;s possible to overrun a remote server and it might be faster to pull 8 or 16 parallel threads instead of 32 or 64 depending on the nature of the remote machine.&lt;/p&gt;

&lt;p&gt;Article describing tool (for citations):&lt;/p&gt;

&lt;p&gt;O. Tange (2011): GNU Parallel - The Command-Line Power Tool, ;login: The USENIX Magazine, February 2011:42-47.&lt;/p&gt;

&lt;p&gt;Authors&#39; website for obtaining code:&lt;/p&gt;

&lt;p&gt;http://www.gnu.org/software/parallel/&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Maps with Leaflet and LeafletR</title>
      <link>http://vielmetti.github.io/post/2015/2015-03-02-maps-with-leaflet-and-leafletr/</link>
      <pubDate>Mon, 02 Mar 2015 01:09:35 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-03-02-maps-with-leaflet-and-leafletr/</guid>
      <description>&lt;pre&gt;
&gt; style &lt;- styleGrad(prop=&#34;score&#34;, breaks=seq(50,100,by=10) ,style.val=rev(rainbow(5)), leg=&#34;score&#34;)
&gt; leaflet(data=&#34;/Users/emv/tmp/N.geojson&#34;,dest=tempdir(),popup=&#34;*&#34;,style=style)
&lt;/pre&gt;

&lt;p&gt;So, progress.&lt;/p&gt;

&lt;p&gt;One process, written in python, takes an Excel file provided by the county and creates a GeoJSON file from it. Addresses in the file are geocoded. The original file has a set of restaurant inspection reports and three kinds of inspection problems found; I add a fourth &#34;score&#34; variable that&#39;s derived in some way from those three.&lt;/p&gt;

&lt;p&gt;A second process (code above) is in R using the LeafletR graphing package. It in turn takes the GeoJSON file as originally provided, and writes an HTML file that reads it using the Leaflet maps package.&lt;/p&gt;

&lt;p&gt;A screenshot of the result is below:&lt;/p&gt;

&lt;p&gt;&lt;a class=&#34;asset-img-link&#34;  href=&#34;http://vielmetti.typepad.com/.a/6a00d8341c4f1a53ef01b7c7572bc9970b-pi&#34;&gt;&lt;img class=&#34;asset  asset-image at-xid-6a00d8341c4f1a53ef01b7c7572bc9970b img-responsive&#34; style=&#34;width: 600px; display: block; margin-left: auto; margin-right: auto;&#34; alt=&#34;Screen Shot 2015-03-02 at 12.56.42 AM&#34; title=&#34;Screen Shot 2015-03-02 at 12.56.42 AM&#34; src=&#34;http://vielmetti.typepad.com/.a/6a00d8341c4f1a53ef01b7c7572bc9970b-600wi&#34; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Some big caveats.&lt;/p&gt;

&lt;p&gt;My color palette is all wrong - I need to think that through. &lt;/p&gt;

&lt;p&gt;This process is based on a single monthly Excel file, and should be updated to include all recent inspections and not just a single month.&lt;/p&gt;

&lt;p&gt;The map needs labels of some sort. (How they will look when everything is smushed together, don&#39;t know.)&lt;/p&gt;

&lt;p&gt;It would be nice to have HTML links to the Arborwiki page for each restaurant, and to a deep link for the inspections itself.&lt;/p&gt;

&lt;p&gt;The geocoder is a bit slow, and I should cache previous results so that it goes faster in future months.&lt;/p&gt;

&lt;p&gt;RESTAURANT NAMES ARE IN ALL CAPS AND THAT&#39;S SHOUTING.&lt;/p&gt;

&lt;p&gt;Leaflet can do all sorts of things and I&#39;ve hardly scratched the surface.&lt;/p&gt;

&lt;p&gt;I probably could do this all in R - or all in Python - but I&#39;m trying to spin up on both systems &amp;amp; thus really want to use each for what they are good at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>using &#34;jq&#34; for command line web applications for civic data</title>
      <link>http://vielmetti.github.io/post/2014/2014-10-05-using-jq-for-command-line-web-applications-for-civic-data/</link>
      <pubDate>Sun, 05 Oct 2014 09:03:34 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2014/2014-10-05-using-jq-for-command-line-web-applications-for-civic-data/</guid>
      <description>&lt;p&gt;One of the tools that I rediscovered and have been really happy for
having done so is &amp;ldquo;jq&amp;rdquo;, a command line tool that bills itself as
&amp;ldquo;awk for json&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been writing awk code since 1985, and some limited subset
of it is something that I know really, really well. awk, however,
is from the punchcard era, and as such it likes to deal with records
that are all on one line each. Parsing JSON in awk is very clumsy
and ad hoc and really doesn&amp;rsquo;t work all that well. Since most Internet
APIs these days have some kind of JSON encoding, it means that you
can&amp;rsquo;t simply dash off an awk one-liner to consume and transform
Internet input data.&lt;/p&gt;

&lt;p&gt;jq fixes that situation. Here for example is a one line renderings of a common task I look to solve with municipal data as a test of any new tool development: analysis of parking data. This code sample prints the total number of open spaces in the Ann Arbor Downtown Development Authority&amp;rsquo;s garages:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;curl -s http://www.a2dda.org/map/AADDACount.json |
  jq &#34;[.countdata[].spacesavail | tonumber] | add&#34; &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&amp;rsquo;m not going to try to explain how jq works, except to note that
it&amp;rsquo;s constructed in order to be a filter: data comes in one JSON
object at a time, and the script iterates over them, transforming
them in some way and then passing JSON out the other end. This makes
it perfect for ad hoc Unix pipeline efforts where you&amp;rsquo;re chipping
away at a data set trying to make sense of it by successively
refining it as you go.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve built jq pipelines for this Ann Arbor parking data, for AAATA
bus system data, and for the Marquette Park Cemetery data. The
parking data is straightforward, since it exits the system as JSON.
Bus system data is only incrementally harder; it started either as
HTML or as XML, and for that you want to use &amp;ldquo;tidy&amp;rdquo; and &amp;ldquo;xml2json&amp;rdquo;
in your pipeline. The Park Cemetery data set started as JSON via
the Socrata SODA API, but I needed little bits of &amp;ldquo;sed&amp;rdquo; and &amp;ldquo;perl&amp;rdquo;
to smooth out some rough edges in the source data; it really wants
to end up as GeoJSON when I&amp;rsquo;m done, but it isn&amp;rsquo;t there quite yet.&lt;/p&gt;

&lt;p&gt;Shell programming is my favorite programming environment. Any time
I can take a set of well-understood tools and crunch through big
data sets with only a few lines of code, I&amp;rsquo;m happy. The challenge
of shell programming is that it&amp;rsquo;s full of opportunities to get
things just a little bit wrong with parsing; by making JSON the
data format that&amp;rsquo;s shoveled between programs rather than a flat
one-record-per-line text format, you open up the opportunity for
pulling apart rather complex structures and manipulating them with
hardly any work.&lt;/p&gt;

&lt;p&gt;For further reading, see Jeroen Janssens new book &lt;a
href=&#34;http://datascienceatthecommandline.com/&#34;&gt;Data Science at the
Command Line&lt;/a&gt; which works you way through dozens of tools like
this that can help manage big data without big programs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Programming your new radio with CHIRP</title>
      <link>http://vielmetti.github.io/post/2013/2013-11-24-programming-your-new-radio-with-chirp/</link>
      <pubDate>Sun, 24 Nov 2013 16:45:56 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-11-24-programming-your-new-radio-with-chirp/</guid>
      <description>&lt;p&gt;From the &lt;a href=&#34;http://chirp.danplanet.com/projects/chirp/wiki/Home&#34;&gt;CHIRP web site&lt;/a&gt; -&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;CHIRP is a free, open-source tool for programming your amateur radio. It supports a large number of manufacturers and models, as well as provides a way to interface with multiple data sources and formats.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The basic idea is that rather than learning the peculiarities of your radio&#39;s programming interface, you use CHIRP which has access to databases like &lt;a href=&#34;http://www.radioreference.com&#34;&gt;Radio Reference&lt;/a&gt; and &lt;a href=&#34;http://www.repeaterbook.com/&#34;&gt;RepeaterBook&lt;/a&gt; to find the channels you want to have easy access to. Programming the device should just be a matter of loading in the set you want, attaching your radio to your computer via a programming cable, and selecting &#34;Upload to Radio&#34;.&lt;/p&gt;

&lt;p&gt;My new radio is on its way, so I&#39;ll update this when I get it to work! So far the application was easy to install (you have to install a Python runtime on OS X before it works) and it was easy to get the Washtenaw county repeater list from &lt;a href=&#34;http://www.repeaterbook.com/&#34;&gt;RepeaterBook&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;UPDATED: It worked the first time! Here&#39;s what I had to do to make it go smoothly.&lt;/p&gt;

&lt;p&gt;First, before you upload channels to your radio, you have to download its current configuration. This gets all of the settings out of the system.&lt;/p&gt;

&lt;p&gt;Second, after you are done uploading the channels, unplug the programming cable from the radio. This should be obvious? but somehow it wasn&#39;t. Once I unplugged things everything worked just fine.&lt;/p&gt;

&lt;p&gt;Third, make sure that you pick the right radio that you are connecting to or else unpredictable things can happen.&lt;/p&gt;

&lt;p&gt;I found the walk-through at &lt;a href=&#34;http://www.miklor.com/COM/UV_CHIRP.php&#34;&gt;Miklor&#39;s CHIRP Software Guide&lt;/a&gt; to be useful and helpful, and it suggested some additional features (like setting channels to be receive-only) that will probably get me to re-program the radio a few times before I&#39;m done.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>a few very small mobile apps, as I learn jQuery Mobile</title>
      <link>http://vielmetti.github.io/post/2013/2013-10-11-a-few-very-small-mobile-apps-as-i-learn-jquery-mobile/</link>
      <pubDate>Fri, 11 Oct 2013 01:29:30 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-10-11-a-few-very-small-mobile-apps-as-i-learn-jquery-mobile/</guid>
      <description>&lt;p&gt;I&#39;m putting together a few mobile apps (in the form of mobile web sites) that are designed for small-screen phone use. Here&#39;s what&#39;s in the works. Each of these are likely to change over time, so don&#39;t get too fond of anything just yet.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;http://vielmetti.typepad.com/m/a2trees.html&#34;&gt;a2trees&lt;/a&gt; app provides some kind of on-the-go listing of street trees in Ann Arbor that are interesting. The observation that there is a great apple crop in 2013 and that there are city trees laden with nice apples just waiting to be picked was the motivation. It&#39;s really bare-bones now, with not more more in the way of detail than my old &lt;a href=&#34;http://vielmetti.typepad.com/vacuum/2009/07/amelanchier-shadbush-juneberry-sugar-plum-inventory-for-ann-arbor-2009.html&#34;&gt;juneberry listing&lt;/a&gt; post, except neatly set up for mobile use.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;http://vielmetti.typepad.com/m/index.html&#34;&gt;mobile web&lt;/a&gt; app is self-referential in that it tries to collect useful bookmarks to mobile-ready versions of things like newspaper, bus, weather, netnews, and other web pages specially formatted for mobile use. I got tired of typing in the URL to fetch the bus listing so I put it on a menu. This is an up-to-dated version of the list I kept of &lt;a href=&#34;http://www.monkey.org/~emv/m/&#34;&gt;mobile sites on monkey.org&lt;/a&gt; dating back about 5 years from when I had a Blackberry and was collecting same. The project is &lt;a href=&#34;http://github.com/vielmetti/mobile&#34;&gt;up on Github&lt;/a&gt; (and has been for the past 5 years!) but there&#39;s not much more to look at than data. Please do feel free to give me feedback there as well as here.&lt;/p&gt;

&lt;p&gt;Finally two power outage related mobile sites. The &lt;a href=&#34;http://vielmetti.typepad.com/power-outage-maps/index.html&#34;&gt;mobile power outage maps&lt;/a&gt; collection is a slow but sure approach to turning my popular &lt;a href=&#34;http://vielmetti.typepad.com/vacuum/2011/06/power-outage-maps.html&#34;&gt;power outage maps&lt;/a&gt; blog post into something more tidy for the small screen. The state it&#39;s in is functional but not complete, and I expect I&#39;ll chip away at it as storms or outages warrant. A second and new app for me is a &lt;a href=&#34;http://vielmetti.typepad.com/power-outage-maps/index-ziplookup.html&#34;&gt;utility company finder&lt;/a&gt; site that takes as its input the first three digits of a zip code and returns the utility companies that serve that area, or type the utility name and get back a list of 3-digit zips it serves. The big caveats on this are that it&#39;s slow, slow, slow, and that the data set it&#39;s derived from is nominally from 2011 but shows many signs of not being kept up to date with utility mergers and name changes since then.&lt;/p&gt;

&lt;p&gt;All of these &#34;mobile&#34; things are browser-based right now, so you can try them from whatever system you are likely to be typing at. They use &lt;a href=&#34;http://jquerymobile.com&#34;&gt;jQuery Mobile&lt;/a&gt; for the fancy bits, and I&#39;m pretty happy so far in just how far I get with that system using HTML do to the work and not having to write a bunch of Javascript to get things to work. On the server side I have been generating these as static sites using old-fashioned Unix shell scripts and makefiles, and though it&#39;s not elegant by any means, it is well within exactly the kind of coding environment I&#39;ve been using since the 1980s.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Taking inventory of old Github projects</title>
      <link>http://vielmetti.github.io/post/2013/2013-08-12-taking-inventory-of-old-github-projects/</link>
      <pubDate>Mon, 12 Aug 2013 23:52:52 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-08-12-taking-inventory-of-old-github-projects/</guid>
      <description>&lt;p&gt;Setting up &lt;a href=&#34;http://octopress.org&#34;&gt;Octopress&lt;/a&gt; has given me a chance to look through some of
&lt;a href=&#34;https://github.com/vielmetti&#34;&gt;my old Github repositories&lt;/a&gt; and re-assess what&#39;s there and how to 
improve on them. &lt;/p&gt;

&lt;p&gt;This is more like a wish list than an actual set of directions, and it
reflects how much the world has moved since I first signed up for a
github account.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/vielmetti/aadl-amazon-linky&#34;&gt;aadl-amazon-linky&lt;/a&gt; and &lt;a href=&#34;http://vielmetti.typepad.com/superpatron&#34;&gt;superpatron&lt;/a&gt;. Both of these are interfaces
to the &lt;a href=&#34;http://aadl.org&#34;&gt;Ann Arbor District Library&lt;/a&gt; catalog, which has a very accessible
programming interface with things like RSS feeds for catalog searches.
I&#39;d like to go back and revisit two parts of this. One was a Greasemonkey
plugin to put library results in Amazon; that should be a Chrome plugin.
The second was a &#34;&lt;a href=&#34;http://www.flickr.com/photos/edward-vielmetti/79567788/&#34;&gt;wall of books&lt;/a&gt;&#34; report displaying an RSS query as a
page full of book cover images. Of the two, the second looks easiest to
recreate; I just checked in some new code, &lt;a href=&#34;https://github.com/vielmetti/superpatron/blob/master/tools/wall-by-keyword.sh&#34;&gt;wall by keyword&lt;/a&gt;, which does
the trick.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/vielmetti/vielmetti-shelltools&#34;&gt;vielmetti-shelltools&lt;/a&gt;. This is a small collection of shell scripts
that I carry around with me and put on whatever system I happen to be
working on. It would be worthwhile to go back through and compare
what I used then with what I use now and refresh the collection.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/vielmetti/postcard&#34;&gt;postcard&lt;/a&gt;. This was a hopeful project to use various web-to-postcard
APIs to generate custom postcards on the fly from the command line. Alas,
several of those APIs have disappeared. The real action in this market is
sending a real postcard from your iPhone or Android phone, with products
like &lt;a href=&#34;http://postagramapp.com/&#34;&gt;Postagram&lt;/a&gt; leading the way. The other neat feature is to go to a drugstore
and make an instant print, then stick a stamp on the back and mail it.
(&lt;a href=&#34;http://communitynetworking2008.wordpress.com/&#34;&gt;Steve Cisler&lt;/a&gt; taught me that trick.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/vielmetti/twitter-mutual-friends&#34;&gt;twitter-mutual-friends&lt;/a&gt;. Once upon a time, the Twitter API was so
simple that you could write a useful application in four lines of shell
script. Now the API has improved itself, and it&#39;s gotten a lot more 
complicated. Look at simple apps like &lt;a href=&#34;https://github.com/gianu/latest_tweets&#34;&gt;latest_tweets&lt;/a&gt; by gianu to
get an idea of what you&#39;re up against now.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/vielmetti/mobile&#34;&gt;mobile&lt;/a&gt;. Again, once upon a time, I had a Blackberry phone which
had the world&#39;s worst usable web browser. Fortunately there were enough
web sites that had a minimalist presentation that I was able to put
together a directory of workable sites, which I used for quite a while.
Now I have an Android phone that runs Chrome as well as apps and I don&#39;t
need the list of sites quite so much; still, it&#39;s worthwhile to have
a place to collect them when I find them.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So when it&#39;s time to write some code here are some ideas for where
to start again!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>octopress up and running</title>
      <link>http://vielmetti.github.io/post/2013/2013-08-11-octopress-up-and-running/</link>
      <pubDate>Sun, 11 Aug 2013 21:56:54 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-08-11-octopress-up-and-running/</guid>
      <description>&lt;p&gt;I am using Octopress to build a new web site at &lt;a href=&#34;http://vielmetti.github.io&#34;&gt;http://vielmetti.github.io&lt;/a&gt;. This looks like it will be a good place as any to write about code and any github projects I am working on. I will keep writing about everything else here.&lt;/p&gt;

&lt;p&gt;To write in Octopress you put files in a directory written in Markdown. Then you use a command line tool called &#39;rake&#39;, the Ruby version of &#39;make&#39;, to do the publishing. Files that have changed get checked in to github. Then the whole site is put into static files, so that it all loads fast.&lt;/p&gt;

&lt;p&gt;Amazing how much more time you have for hacking when you are not on Facebook.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>