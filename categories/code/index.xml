<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Code on Vacuum weblog from Edward Vielmetti</title>
    <link>http://vielmetti.github.io/categories/code/</link>
    <description>Recent content in Code on Vacuum weblog from Edward Vielmetti</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jul 2015 02:30:00 -0400</lastBuildDate>
    
	<atom:link href="http://vielmetti.github.io/categories/code/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>mitmproxy</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-31-mitmproxy/</link>
      <pubDate>Fri, 31 Jul 2015 02:30:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-31-mitmproxy/</guid>
      <description>In his An internet x-ray machine for the masses, Paul Ohm writes a lucid introduction to mitmproxy, a man-in-the-middle proxy server that allows you to get between your browser and the Internet and poke at (and change) the traffic going between the two.
http://mitmproxy.org is the home of mitmproxy. It&amp;rsquo;s the work of Aldo Cortesi and a cast of hundreds of contributors on github at https://github.com/mitmproxy/mitmproxy . I used the OS X binary distribution from the download page.</description>
    </item>
    
    <item>
      <title>bocker is a subset of Docker in 100 lines of shell script</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-21-docker-in-bash/</link>
      <pubDate>Tue, 21 Jul 2015 18:48:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-21-docker-in-bash/</guid>
      <description>bocker is Docker (or at least a good sized subset of it) in 100 lines of shell script. I suppose the point is that even though there&amp;rsquo;s a huge world of hype surrounding containerization as a next step of systems management, when you get down to it, it&amp;rsquo;s just not that complicated.</description>
    </item>
    
    <item>
      <title>Daily coffee and wifi, ERC South Main</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-21-daily-coffee-wifi-erc-south-main/</link>
      <pubDate>Tue, 21 Jul 2015 10:30:00 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-21-daily-coffee-wifi-erc-south-main/</guid>
      <description>Espresso over ice at ERC South Main. This is now my favorite summer drink. Served in a cup with enough ice and you get the makings of a very strong iced latte, just add a little half and half.
The work of the morning is finishing up yesterday&amp;rsquo;s work on sending postcards with Lob.com. Key to this effort is resizing your favorite images so that they meet the template. Fortunately I had the presence of mind seven years ago to write up my notes on using sips and Imagemagick for image manipulation and that helped.</description>
    </item>
    
    <item>
      <title>Daily coffee and wifi at Biggby Packard</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-20-daily-coffee-wifi-packard-biggby/</link>
      <pubDate>Mon, 20 Jul 2015 11:13:43 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-20-daily-coffee-wifi-packard-biggby/</guid>
      <description>It&amp;rsquo;s a warm but pleasant mid-summer late Monday morning, and I&amp;rsquo;m visiting the first cafe inbound on a walk to town. Biggby Packard is where I end up when the inbound bus schedule timing is just so.
Summertime cafes near campus are odd. There&amp;rsquo;s not really enough here to motivate someone to drive here for coffee, so it draws people from the surrounding neighborhood and from the athletic campus. I&amp;rsquo;ve been in here before when I was the only patron for more than an hour but this morning there&amp;rsquo;s a few more people sitting typing.</description>
    </item>
    
    <item>
      <title>lob a postcard: printer sends cards via API</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-19-lob-a-postcard-printer/</link>
      <pubDate>Sun, 19 Jul 2015 22:05:18 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-19-lob-a-postcard-printer/</guid>
      <description>Lob.com has an API to send postcards-as-a-service ($0.70 per each, full custom both sides). Details at https://lob.com/services/postcards . It works, but all of the user interface is up to you; if you know a good service for delivering a single full-custom postcard with postage that actually has a user interface and not an API for less than $1.00 each, let me know and I&amp;rsquo;ll update here.
I&amp;rsquo;ve started checking in a few tiny utility programs that exercise the Lob API.</description>
    </item>
    
    <item>
      <title>Levenshtein distance for approximate match</title>
      <link>http://vielmetti.github.io/post/2015/2015-07-17-levenshtein-distance-for-approximate-match/</link>
      <pubDate>Fri, 17 Jul 2015 16:11:41 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-07-17-levenshtein-distance-for-approximate-match/</guid>
      <description>The problem, simply stated, is that of typoes and inconsistent spelling and pluraliziation. Let&amp;rsquo;s say you have a collection of text that you want to annotate with some metadata, like categories and tags. You don&amp;rsquo;t want to set aside ahead of time exactly which tags you want to use, but you want to catch through some test or lint step that you&amp;rsquo;ve done something wrong by typing &amp;ldquo;apples&amp;rdquo; into a field that really has &amp;ldquo;apple&amp;rdquo; most of the time.</description>
    </item>
    
    <item>
      <title>Using a squid cache to make automated data collection a bit less rude</title>
      <link>http://vielmetti.github.io/post/2015/2015-06-28-using-a-squid-cache-to-make-automated-data-collection-a-bit-less-rude/</link>
      <pubDate>Sun, 28 Jun 2015 15:23:26 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-06-28-using-a-squid-cache-to-make-automated-data-collection-a-bit-less-rude/</guid>
      <description>squid is a web caching system. Instead of browsing directly to a site, you point your browser at a squid cache, and the cache serves up cached copies of the data you are asking for. If squid has an out of date copy of the data it fetches a new one for you. The goal is to be a transparent cache, and to be nearly as fast as direct access when you don&#39;t have the data, and way faster when you do.</description>
    </item>
    
    <item>
      <title>Using GNU Parallel to speed up network operations</title>
      <link>http://vielmetti.github.io/post/2015/2015-06-24-using-gnu-parallel-to-speed-up-network-operations/</link>
      <pubDate>Wed, 24 Jun 2015 10:23:20 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-06-24-using-gnu-parallel-to-speed-up-network-operations/</guid>
      <description>My current laptop (a MacBook Air) has a plenty fast processor and super fast disk. This means that the usual bottleneck for system operations is the network, not the computer itself. I go from wifi spot to other wifi spot enough that I know that performance varies a lot, and especially there are a lot of places where the network is really not fast enough.
Enter GNU Parallel. This little tool lets you spawn a whole series of processes, with the next one starting when the previous one completes.</description>
    </item>
    
    <item>
      <title>Maps with Leaflet and LeafletR</title>
      <link>http://vielmetti.github.io/post/2015/2015-03-02-maps-with-leaflet-and-leafletr/</link>
      <pubDate>Mon, 02 Mar 2015 01:09:35 -0400</pubDate>
      
      <guid>http://vielmetti.github.io/post/2015/2015-03-02-maps-with-leaflet-and-leafletr/</guid>
      <description>style leaflet(data=&#34;/Users/emv/tmp/N.geojson&#34;,dest=tempdir(),popup=&#34;*&#34;,style=style)  So, progress.
One process, written in python, takes an Excel file provided by the county and creates a GeoJSON file from it. Addresses in the file are geocoded. The original file has a set of restaurant inspection reports and three kinds of inspection problems found; I add a fourth &#34;score&#34; variable that&#39;s derived in some way from those three.
A second process (code above) is in R using the LeafletR graphing package.</description>
    </item>
    
    <item>
      <title>using &#34;jq&#34; for command line web applications for civic data</title>
      <link>http://vielmetti.github.io/post/2014/2014-10-05-using-jq-for-command-line-web-applications-for-civic-data/</link>
      <pubDate>Sun, 05 Oct 2014 09:03:34 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2014/2014-10-05-using-jq-for-command-line-web-applications-for-civic-data/</guid>
      <description>One of the tools that I rediscovered and have been really happy for having done so is &amp;ldquo;jq&amp;rdquo;, a command line tool that bills itself as &amp;ldquo;awk for json&amp;rdquo;.
I&amp;rsquo;ve been writing awk code since 1985, and some limited subset of it is something that I know really, really well. awk, however, is from the punchcard era, and as such it likes to deal with records that are all on one line each.</description>
    </item>
    
    <item>
      <title>Programming your new radio with CHIRP</title>
      <link>http://vielmetti.github.io/post/2013/2013-11-24-programming-your-new-radio-with-chirp/</link>
      <pubDate>Sun, 24 Nov 2013 16:45:56 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-11-24-programming-your-new-radio-with-chirp/</guid>
      <description>From the CHIRP web site -
 CHIRP is a free, open-source tool for programming your amateur radio. It supports a large number of manufacturers and models, as well as provides a way to interface with multiple data sources and formats.
 The basic idea is that rather than learning the peculiarities of your radio&#39;s programming interface, you use CHIRP which has access to databases like Radio Reference and RepeaterBook to find the channels you want to have easy access to.</description>
    </item>
    
    <item>
      <title>a few very small mobile apps, as I learn jQuery Mobile</title>
      <link>http://vielmetti.github.io/post/2013/2013-10-11-a-few-very-small-mobile-apps-as-i-learn-jquery-mobile/</link>
      <pubDate>Fri, 11 Oct 2013 01:29:30 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-10-11-a-few-very-small-mobile-apps-as-i-learn-jquery-mobile/</guid>
      <description>I&#39;m putting together a few mobile apps (in the form of mobile web sites) that are designed for small-screen phone use. Here&#39;s what&#39;s in the works. Each of these are likely to change over time, so don&#39;t get too fond of anything just yet.
The a2trees app provides some kind of on-the-go listing of street trees in Ann Arbor that are interesting. The observation that there is a great apple crop in 2013 and that there are city trees laden with nice apples just waiting to be picked was the motivation.</description>
    </item>
    
    <item>
      <title>Taking inventory of old Github projects</title>
      <link>http://vielmetti.github.io/post/2013/2013-08-12-taking-inventory-of-old-github-projects/</link>
      <pubDate>Mon, 12 Aug 2013 23:52:52 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-08-12-taking-inventory-of-old-github-projects/</guid>
      <description>Setting up Octopress has given me a chance to look through some of my old Github repositories and re-assess what&#39;s there and how to improve on them. This is more like a wish list than an actual set of directions, and it reflects how much the world has moved since I first signed up for a github account.
 aadl-amazon-linky and superpatron. Both of these are interfaces to the Ann Arbor District Library catalog, which has a very accessible programming interface with things like RSS feeds for catalog searches.</description>
    </item>
    
    <item>
      <title>octopress up and running</title>
      <link>http://vielmetti.github.io/post/2013/2013-08-11-octopress-up-and-running/</link>
      <pubDate>Sun, 11 Aug 2013 21:56:54 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-08-11-octopress-up-and-running/</guid>
      <description>I am using Octopress to build a new web site at http://vielmetti.github.io. This looks like it will be a good place as any to write about code and any github projects I am working on. I will keep writing about everything else here.
To write in Octopress you put files in a directory written in Markdown. Then you use a command line tool called &#39;rake&#39;, the Ruby version of &#39;make&#39;, to do the publishing.</description>
    </item>
    
    <item>
      <title>Hacker News summary, 1 June 2013, 11:15 p.m. EST edition</title>
      <link>http://vielmetti.github.io/post/2013/2013-06-01-hacker-news-summary-1-june-2013-1115-pm-est-edition/</link>
      <pubDate>Sat, 01 Jun 2013 23:57:52 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-06-01-hacker-news-summary-1-june-2013-1115-pm-est-edition/</guid>
      <description>A late night Hacker News summary, pulling from&amp;#0160;https://news.ycombinator.com/.
1.&amp;#0160;Apple betrayed by its own law firm.&amp;#0160;John&amp;#0160;J.&amp;#0160;McAleese, III, an attorney at one of&amp;#0160;Apple&amp;#39;s own go-to law firms, (Morgan, Lewis &amp;amp; Bockius), was behind a patent troll lawsuit from Flatworld Interactives. McAleese has been digitally erased from the Morgan Lewis site. (Ars Technica) &amp;quot;I predict this is going to be as much fun to watch as the Prenda Law case!&amp;quot;&amp;#0160;( 4 comments )&amp;#0160;</description>
    </item>
    
    <item>
      <title>Hacker News summary, Wednesday 29 May 2013, 5:00 p.m. EST edition</title>
      <link>http://vielmetti.github.io/post/2013/2013-05-29-hacker-news-summary-wednesday-29-may-2013-500-pm-est-edition/</link>
      <pubDate>Wed, 29 May 2013 17:48:13 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-05-29-hacker-news-summary-wednesday-29-may-2013-500-pm-est-edition/</guid>
      <description>Welcome to the Wednesday version of a daily Hacker News summary. In the news today: a new Gmail interface, a Drupal security breach, how to negotiate a job offer, Bill Gates goes to India, and Mary Meeker&#39;s Internet Trends.
I&#39;m going to diverge a little from past practice and pick and choose a little more carefully than normally, going a little beyond the top 8 to find the stories that actually interest me.</description>
    </item>
    
    <item>
      <title>Hacker News summary, Tuesday 28 May 2013, 9:45 p.m edition</title>
      <link>http://vielmetti.github.io/post/2013/2013-05-28-hacker-news-summary-tuesday-28-may-2013-945-pm-edition/</link>
      <pubDate>Tue, 28 May 2013 22:22:27 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-05-28-hacker-news-summary-tuesday-28-may-2013-945-pm-edition/</guid>
      <description>A late evening version of Hacker News for Tuesday 28 May 2013. I&amp;#39;ve added links to the comments for each entry, and try to pull out a useful quote from the comments if there are any that are easy to find. Of interest: Pixar raytracing, Liberty Reserve money laundering, and Harvard email snooping.
1. A breakdown of github pull requests by acceptance rate, for a variety of languages and projects. If you want to get your pull request accepted, don&amp;#39;t write C++, write Scala; and contribute to projects like Akka&amp;#0160;and&amp;#0160;backbone-fundamentals that take 80+% of pull requests.</description>
    </item>
    
    <item>
      <title>Hacker News summary for Tuesday 28 May 2013, 7:00 a.m. edition</title>
      <link>http://vielmetti.github.io/post/2013/2013-05-28-hacker-news-summary-for-tuesday-28-may-2013-700-am-edition/</link>
      <pubDate>Tue, 28 May 2013 07:45:12 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-05-28-hacker-news-summary-for-tuesday-28-may-2013-700-am-edition/</guid>
      <description>Here&amp;#39;s a summary of the top stories on Hacker News at this moment, as part of daily exercise to do a closer reading of the tech news. See On Summarization for more background.
1. &amp;quot;Opera for desktop has not only been redesigned; it&amp;#39;s also completely re-engineered under the hood. With the Chromium engine, users get a standards-compliant and high-performance browser.&amp;quot; (Opera) &amp;quot;The price of switching to Chromium: Opera.app = 37.8 MB, Opera Next.</description>
    </item>
    
    <item>
      <title>Hacker News summary, Monday 27 May 2013, 3:00 p.m. edition</title>
      <link>http://vielmetti.github.io/post/2013/2013-05-27-hacker-news-summary-monday-27-may-2013-300-pm-edition/</link>
      <pubDate>Mon, 27 May 2013 15:19:43 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-05-27-hacker-news-summary-monday-27-may-2013-300-pm-edition/</guid>
      <description>A summary of Hacker News from 3:00 p.m. on Memorial Day. It&amp;#39;s getting faster to produce these, but it still takes at least a minute or two per each.
I wonder about the churn rate of the Hacker News front page. How long do you have to wait to ensure that the top 10 posts have all cycled out? Every day is clearly enough, but I&amp;#39;m suspecting that it might take as little as 12 hours to cycle through what passes for news.</description>
    </item>
    
    <item>
      <title>Hacker News summary for Sunday 26 May 2013, 6:00 p.m. EST edition</title>
      <link>http://vielmetti.github.io/post/2013/2013-05-26-hacker-news-summary-for-sunday-26-may-2013-600-pm-est-edition/</link>
      <pubDate>Sun, 26 May 2013 18:18:39 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-05-26-hacker-news-summary-for-sunday-26-may-2013-600-pm-est-edition/</guid>
      <description>Compiled hastily, here&amp;#39;s a summary of today&amp;#39;s Hacker News top 10. Based solely on the top 10, it&amp;#39;s a slow news day.
1. &amp;quot;If you try to get several regular polygons to meet snugly at a point in the plane, what’s the most sides any of the polygons can have? The answer is 42.&amp;quot; (Azimuth Project) Some observations of mathematical questions for which the answer is 42 or a multiple thereof, in time for Towel Day.</description>
    </item>
    
    <item>
      <title>Hacker News summary for Saturday, 25 May 2013, 10:15 p.m. EST edition</title>
      <link>http://vielmetti.github.io/post/2013/2013-05-25-hacker-news-summary-for-saturday-25-may-2013-1015-pm-est-edition/</link>
      <pubDate>Sat, 25 May 2013 22:49:15 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-05-25-hacker-news-summary-for-saturday-25-may-2013-1015-pm-est-edition/</guid>
      <description>The top 10 stories on Hacker News this instant, summarized quickly. It&amp;#39;s taking me about 3 minutes per article to read and digest it well enough to write down a few words about it.
1. Poll: &amp;quot;What is your hourly rate, or your monthly salary converted into hourly rate (divided by ~165 hours) in USD?&amp;quot; (csomar) Much discussion in the comments as to whether people are charging too little.
2. 98% of venture capitalists aren&amp;#39;t dumb (Mark Suster), a response to &amp;quot;Dear Dumb VC&amp;quot; (Andy Dunn).</description>
    </item>
    
    <item>
      <title>Hacker News summary for Friday, 24 May 2013, 8:00 p.m. EST edition</title>
      <link>http://vielmetti.github.io/post/2013/2013-05-24-hacker-news-summary-for-friday-24-may-2013-800-pm-est-edition/</link>
      <pubDate>Fri, 24 May 2013 20:32:35 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2013/2013-05-24-hacker-news-summary-for-friday-24-may-2013-800-pm-est-edition/</guid>
      <description>An attempt to catch the top news of Hacker News on a Friday evening and summarize the top 10 stories; I won&amp;#39;t make any decisions about what should be in the top 10, just note them here with a summary. It took me about 30 minutes to summarize 10 stories, without being selective about which ones were important.
1. Ben Howdle is &amp;quot;Too scared to write a line of code&amp;quot; (Medium).</description>
    </item>
    
    <item>
      <title>You are likely to be eaten by a grue.</title>
      <link>http://vielmetti.github.io/post/2011/2011-01-21-you-are-likely-to-be-eaten-by-a-grue/</link>
      <pubDate>Fri, 21 Jan 2011 22:25:46 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2011/2011-01-21-you-are-likely-to-be-eaten-by-a-grue/</guid>
      <description>The video, entitled &#34;It is pitch dark&#34;, from nerdcore hip-hop grandmaster MC Frontalot.

The lyrics, in part:
You are likely to be eaten by a grue. If this predicament seems particularly cruel, consider whose fault it could be: not a torch or a match in your inventory. What is a grue?
The grue is a sinister, lurking presence in the dark places of the earth. Its favorite diet is adventurers, but its insatiable appetite is tempered by its fear of light.</description>
    </item>
    
    <item>
      <title>Map Warper: stretch an old map to fit the new landscape</title>
      <link>http://vielmetti.github.io/post/2009/2009-06-24-map-warper-stretch-an-old-map-to-fit-the-new-landscape/</link>
      <pubDate>Wed, 24 Jun 2009 22:34:51 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2009/2009-06-24-map-warper-stretch-an-old-map-to-fit-the-new-landscape/</guid>
      <description>http://www.vizworld.com/2009/06/testing-map-warper-beta/
Maitri has a great write-up of Map Warper, a tool for taking old maps and stretching them (rectifying them) to match another base map.&amp;#0160; Tim Waters has developed an open source tool called Map Warper (Beta) into which you can upload a scanned map, georectify it and save it out as an image or a map layer.&amp;#0160; As a former resident of New Orleans, where a transparent recovery and historic preservation are daily uphill battles, this tool can be invaluable in saving and sharing ancient and new maps of the city’s original development and re-development since Hurricane Katrina and The Flood.</description>
    </item>
    
    <item>
      <title>whitehouse.gov: sending data to statse.webtrendslive.com</title>
      <link>http://vielmetti.github.io/post/2009/2009-01-20-whitehousegov-sending-data-to-statsewebtrendslivecom/</link>
      <pubDate>Tue, 20 Jan 2009 22:59:27 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2009/2009-01-20-whitehousegov-sending-data-to-statsewebtrendslivecom/</guid>
      <description>On the page:
&amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;/includes/webtrends.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
in that code:

function WebTrends(){
var that=this;
// begin: user modifiable
this.dcsid=&amp;quot;dcs0l9nq800000ctek411lue6_2c8b&amp;quot;;
 this.domain=&amp;quot;statse.webtrendslive.com&amp;quot;;
this.timezone=-5;
this.fpcdom=&amp;quot;.whitehouse.gov&amp;quot;;
this.onsitedoms=&amp;quot;&amp;quot;;
this.downloadtypes=&amp;quot;xls,doc,pdf,txt,csv,zip&amp;quot;;
this.rightclicktypes=&amp;quot;xls,doc,pdf,txt,csv,zip&amp;quot;;
this.trackevents=true;
this.enabled=true;
this.i18n=false;
this.fpc=&amp;quot;WT_FPC&amp;quot;;
// end: user modifiable
this.DCS={};
this.WT={};
this.DCSext={};
this.images=[];
this.index=0;
this.exre=(function(){return(window.RegExp?new RegExp(&amp;quot;dcs(uri)|(ref)|(aut)|(met)|(sta)|(sip)|(pro)
|(byt)|(dat)|(p3p)|(cfg)|(redirect)|(cip)&amp;quot;,&amp;quot;i&amp;quot;):&amp;quot;&amp;quot;);})();
this.re=(function(){return(window.RegExp?(that.i18n?{&amp;quot;%25&amp;quot;:/\%/g}:{&amp;quot;%09&amp;quot;:/\t/g,&amp;quot;%20&amp;quot;:/ /g,&amp;quot;%23&amp;quot;:/\#
/g,&amp;quot;%26&amp;quot;:/\&amp;amp;/g,&amp;quot;%2B&amp;quot;:/\+/g,&amp;quot;%3F&amp;quot;:/\?/g,&amp;quot;%5C&amp;quot;:/\\/g,&amp;quot;%22&amp;quot;:/\&amp;quot;/g,&amp;quot;%7F&amp;quot;:/\x7F/g,&amp;quot;%A0&amp;quot;:/\xA0/g}):&amp;quot;&amp;quot;);})(
);
}
in the privacy policy:
Browser information collected on the web site: We log IP addresses, which are the locations of computers or networks on the Internet, and analyze them in order to improve the value of our site.</description>
    </item>
    
    <item>
      <title>regime change: before and after on whitehouse.gov</title>
      <link>http://vielmetti.github.io/post/2009/2009-01-20-regime-change-before-and-after-on-whitehousegov/</link>
      <pubDate>Tue, 20 Jan 2009 12:07:00 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2009/2009-01-20-regime-change-before-and-after-on-whitehousegov/</guid>
      <description>$ for n in $(~/bin/range 1 60); do curl -L http://whitehouse.gov -o whitehouse.$n.html; sleep 60; done &amp;amp;
$ ls -ltr
total 1392
-rw-r--r--&amp;#0160; 1 emv&amp;#0160; staff&amp;#0160; 33323 Jan 20 11:46 whitehouse.1.html
-rw-r--r--&amp;#0160; 1 emv&amp;#0160; staff&amp;#0160; 33323 Jan 20 11:47 whitehouse.2.html
-rw-r--r--&amp;#0160; 1 emv&amp;#0160; staff&amp;#0160; 33323 Jan 20 11:48 whitehouse.3.html
-rw-r--r--&amp;#0160; 1 emv&amp;#0160; staff&amp;#0160; 33323 Jan 20 11:49 whitehouse.4.html
-rw-r--r--&amp;#0160; 1 emv&amp;#0160; staff&amp;#0160; 33323 Jan 20 11:50 whitehouse.5.html
-rw-r--r--&amp;#0160; 1 emv&amp;#0160; staff&amp;#0160; 33323 Jan 20 11:51 whitehouse.</description>
    </item>
    
    <item>
      <title>&#34;crush collision&#34;, a new album from The MD5</title>
      <link>http://vielmetti.github.io/post/2008/2008-12-31-crush-collision-a-new-album-from-the-md5/</link>
      <pubDate>Wed, 31 Dec 2008 15:51:36 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2008/2008-12-31-crush-collision-a-new-album-from-the-md5/</guid>
      <description>No, not really, but wouldn&amp;#39;t it be awesome?
This is the team that wrote the paper MD5 considered harmful today: Creating a rogue CA certificate which showed that the security model of HTTPS can be defeated using a combination of attacks on the MD5 hash algorithm plus non-random serial numbers in the popular RapidSSL and FreeSSL certificates.&amp;#0160; They used a cluster of 200 PS3s for a weekend of number crunching.</description>
    </item>
    
    <item>
      <title>stuck on a postcard / postful / curl problem</title>
      <link>http://vielmetti.github.io/post/2008/2008-12-30-stuck-on-a-postcard-postful-curl-problem/</link>
      <pubDate>Tue, 30 Dec 2008 15:00:21 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2008/2008-12-30-stuck-on-a-postcard-postful-curl-problem/</guid>
      <description>FIXED, see the bottom.&amp;#0160; 12/31
rather than give up in total frustration, here&amp;#39;s what I am trying to implement, using &amp;quot;curl&amp;quot; to drive the system.&amp;#0160; This is from the &amp;quot;postful&amp;quot; API docs.
1. Upload the document. To uploading a document, submit a POST to:
http://www.postful.com/service/upload Be sure to include the Content-Type and Content-Length headers and the document itself as the body of the request.
POST /upload HTTP/1.0
Content-Type: application/octet-stream
Content-Length: 301456</description>
    </item>
    
    <item>
      <title>image processing on the mac with sips, ImageMagick - watching DTE restore power, slowly</title>
      <link>http://vielmetti.github.io/post/2008/2008-12-29-image-processing-on-the-mac-with-sips-imagemagick-watching-dte-restore-power-slowly/</link>
      <pubDate>Mon, 29 Dec 2008 15:12:19 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2008/2008-12-29-image-processing-on-the-mac-with-sips-imagemagick-watching-dte-restore-power-slowly/</guid>
      <description>As part of watching DTE slowly restore power to the area, I&amp;#39;ve been pulling down copies of their outage maps.&amp;#0160; These are big PDF files, suitable for framing, that encode a bunch of data in them about where the power is out.&amp;#0160; Here&amp;#39;s some tools I used to get details out of PDF into image formats, (hopefully) to get them back down to a spreadsheet full of numbers.
1.&amp;#0160; Fetch the outage report automatically with curl:</description>
    </item>
    
    <item>
      <title>using &#34;tidy&#34; in a screen scraping pipeline</title>
      <link>http://vielmetti.github.io/post/2008/2008-12-26-using-tidy-in-a-screen-scraping-pipeline/</link>
      <pubDate>Fri, 26 Dec 2008 14:24:24 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2008/2008-12-26-using-tidy-in-a-screen-scraping-pipeline/</guid>
      <description>When the AATA mobile ride track is up, I have a script that runs periodically to decode the web pages and turn them into data.&amp;#0160; The pages are formatted for humans, so I need to do screen scraping on them to reconstruct the original data values.
There are a lot of tools for screen scraping, with each of them appealing to a programmer who has a certain world view of the web and how things are put together.</description>
    </item>
    
    <item>
      <title>How to run Django on Google App Engine - results of the Ann Arbor Google App Engine hackathon</title>
      <link>http://vielmetti.github.io/post/2008/2008-11-17-how-to-run-django-on-google-app-engine---results-of-the-ann-arbor-google-app-engine-hackathon/</link>
      <pubDate>Mon, 17 Nov 2008 11:07:48 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2008/2008-11-17-how-to-run-django-on-google-app-engine---results-of-the-ann-arbor-google-app-engine-hackathon/</guid>
      <description>I&#39;m at the Google App Engine hackathon in Ann Arbor.&amp;nbsp; My goal for the day is to get a Django instance running on top of appengine as much as possible, using as much of the existing code base that&#39;s out there that I can.&amp;nbsp; (This instead of say, hacking a wiki, which is what their sample app is - been there done that.)
Here&#39;s some background reading:
Using Django with Appengine - Shabda Raaj.</description>
    </item>
    
    <item>
      <title>Programming and the &#34;intelligent web&#34;</title>
      <link>http://vielmetti.github.io/post/2008/2008-10-16-programming-and/</link>
      <pubDate>Thu, 16 Oct 2008 21:16:46 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2008/2008-10-16-programming-and/</guid>
      <description>Some notes from the publisher&#39;s sites on new(ish) books on programming a web 2.0 world.&amp;nbsp; Just remember, &amp;quot;every day computers are making people easier and easier to use.&amp;quot;
Programming Collective Intelligence, 1st Edition by Toby Segaran
 Want to tap the power behind search rankings, product recommendations, social bookmarking, and online matchmaking? This fascinating book demonstrates how you can build Web 2.0 applications to mine the enormous amount of data created by people on the Internet.</description>
    </item>
    
    <item>
      <title>Fixing LinkedIn for Groups with Greasemonkey; step one, the naming of the parts</title>
      <link>http://vielmetti.github.io/post/2008/2008-08-20-fixing-linkedin/</link>
      <pubDate>Wed, 20 Aug 2008 15:11:32 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2008/2008-08-20-fixing-linkedin/</guid>
      <description>I use LinkedIn for Groups to manage the Cisco Alumni Association group.&amp;nbsp; One of the qualification steps is that you have to have worked for Cisco in the past (and you&#39;d be surprised how many people apply who haven&#39;t any connection at all).
 The admin UI for that system is clumsy if you have to approve and delete a lot of people - basically there&#39;s no built-in support for checking someone out short of opening up a whole new window with their profile.</description>
    </item>
    
    <item>
      <title>threequel === threequal - of movies, code, and the l33t</title>
      <link>http://vielmetti.github.io/post/2008/2008-05-19-threequel-three/</link>
      <pubDate>Mon, 19 May 2008 18:36:17 +0000</pubDate>
      
      <guid>http://vielmetti.github.io/post/2008/2008-05-19-threequel-three/</guid>
      <description>A few definitions for you, with citations from the wild; spelling is as in the original with Google counts of occurences, if possible.
In short: threequel and 3quel are about movies; threequal is the &#34;===&#34; operator; 3qual is hacker speak. More or less.
threequel (33,900): When I was a kid, I assumed all third installments in a horror series had to capitalize on the ability to turn the “3″ in the title into “3-D.</description>
    </item>
    
  </channel>
</rss>